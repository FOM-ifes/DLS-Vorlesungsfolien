```{r setup-Datenhandling, include=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Karsten Luebke
#%
# ---------------------------------------------------------------------------
source("../prelude.R")
initPart(
    "Datenhandling",  # Dateiname ohne Suffix
    "Datenhandling"     # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages <- getPathToImages()
# ---------------------------------------------------------------------------

library(mosaic)
library(knitr)
library(viridis)
library(gridExtra)

tips <- assertData("tips.csv", "https://goo.gl/whKjnl")
```
```{r echo = FALSE}
library(mosaic)
inspect <- mosaic::inspect # Sonst wir arules::inspect() vielleicht genommen
```

# Data Wrangling

### Cartoon: Cleansing data

```{r echo=FALSE, out.width = "50%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2018/Caption-Contest_02-2018.jpg", "cartoon0218.jpg", pathToImages)
```
"Don't Forget to Clean Your Dirty Data!"^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/february/2018/results) &copy; J.B. Landers, Überschrift J.A. Morrow]


### Preparing data


Frequently data sets need to be prepared before the "real" analysis starts, eg.,

- Select variables: `select()`
- Filter rows: `filter()`
- Mutate (change) or define variables: `mutate()`
- Summarize cases: `summarise()`
- ...

The R package `dplyr`^[automatically loaded by `mosaic`] provides many convenience functions for that purpose.

See the extensive documentation: [http://dplyr.tidyverse.org/index.html](http://dplyr.tidyverse.org/index.html)



### Setup

Read the  *Tipping*^[Bryant, P. G. and Smith, M (1995) Practical Data Analysis: Case Studies in Business Statistics. Homewood, IL: Richard D. Irwin Publishing] data set and load the R package `mosaic`:

```{r, eval=FALSE, message=FALSE}
download.file("https://goo.gl/whKjnl", destfile = "tips.csv")
tips <- read.csv2("tips.csv")

# alternatively: laod the file from your computer:
# tips <- read.csv2(file.choose()) 

library(mosaic) # start R package mosaic
```

### Select variables from data se: `select()`

::: {.small}
```{r, eval=FALSE}
tips %>%
  select(sex, total_bill) %>%
  inspect()
```
```{r, echo=FALSE}
tips %>%
  dplyr::select(sex, total_bill) %>%
  inspect()
```
:::


### Logic 

- Logical *And* ($\land$): `&`: A logical ***And*** between two propositions yields true if and only if both propositions are true.
- Logical Oder ($\lor$): `|`: A logical  ***OR*** between two propositions yields true if at least one of the propositions is true.
- Logical Negation  ($\neg$): `!`


R compares elementwise. 


::: {.scriptsize} 

```{r Logik}
x <- c(TRUE, TRUE)
y <- c(TRUE, FALSE)
x & y
x | y
x | (!y)
```

Use `all()` ($\forall$) and `any()` ($\exists$) to test multiple truth values.

:::

### Exercise `r nextExercise()`: Logical {.exercise type=A-B answer=A}

What's the truth value of: `(TRUE|FALSE) & (FALSE)`

A.  `r (TRUE|FALSE)&(FALSE)`
B.  `r !((TRUE|FALSE)&(FALSE))`

::: {.notes}
`TRUE` or `FALSE` yields `TRUE`. `TRUE` and `FALSE` yields `FALSE`, hence ***A***.
:::

### Exercise `r nextExercise()`: Set theory {.exercise type=yesno answer=no}

```{r, echo=FALSE, fig.align="center", out.width="60%", results=FALSE}
# https://rstudio-pubs-static.s3.amazonaws.com/13301_6641d73cfac741a59c0a851feb99e98b.html
VennDiagram::draw.pairwise.venn(30, 25, 10, category = c("those loving dogs", "those loving cats"),
                                lty = rep("blank", 2), fill = viridis(2, alpha = 0.6), cat.cex=rep(1.5,2), cex=rep(2,3),
                                alpha = rep(0.5, 2), cat.pos = c(0, 0), cat.dist = rep(0.025, 2))
```

True or false: The ***And*** operator ($\land$) selects at least as many cases as the ***Or**  ($\lor$) operator?



- True
- False

::: {.notes}

***False***: Whereas only 10 cases match both conditions  ($\land$, in set notation: $\cap$), 45 cases match *at least* one condition ($\lor$, in set notation: $\cup$)


:::

### Comparing/assessing in R

- equality, ($=$): `==`
- inequality ($\neq$): `!=`
- less than /less than or equal to ($<, \leq$): `<`, `<=`
- greater than/greater than or equal to ($>, \geq$): `>`, `>=`

```{r Vergleich}
4 == 5
4 != 5
4 <= 5
4 > 5
```

### Filter cases (rows of a dataframe): `filter()` {.shrink}

```{r filter}
tips %>%
  filter(sex=="Female" & total_bill>20) %>%
  inspect()
```

### Exercise `r nextExercise()`: Select and filter {.exercise type=essay}

Come up with a data set containing the variable `tip` only, and that only for tables where a smoker paid at dinner.


```{r, include=FALSE}
smokingdinner <- tips %>%
  filter(time=="Dinner" & smoker=="Yes") %>%
  dplyr::select(tip)
```

::: {.notes}
`smokingdinner <- tips %>% filter(time=="Dinner" & smoker=="Yes") %>% select(tip)`  
:::

### Defining/mutating variables (of a data set): `mutate()`

::: {.small}


```{r eval=FALSE}
tips %>%
  mutate(paid=total_bill+tip) %>%
  select(paid) %>%
  inspect()
```
```{r, echo=FALSE}
tips %>%
  mutate(paid=total_bill+tip) %>%
  dplyr::select(paid) %>%
  inspect()
```

:::



### Exercise `r nextExercise()`: Relative tip value {.exercise type=A-B-C answer=B}


How many cases (ie., rows) have a *relative tip* value $\frac{tip}{total\_bill}$ greater than $10\%$?

A.  `r nrow(tips)` 
B.  `r tips %>% mutate(rel=tip/total_bill) %>% filter(rel>0.1) %>% nrow()`
C.  `r tips %>% mutate(rel=tip/total_bill) %>% filter(rel<=0.1) %>% nrow()`

::: {.notes}

***B***: `tips %>% mutate(rel=tip/total_bill) %>% filter(rel>0.1) %>% nrow()`

:::


### Cut variables into groups: `case_when()`


```{r eval=FALSE}
tips %>%
  mutate(bill = case_when(total_bill <= 10 ~ "low",
                          total_bill <= 20 ~ "middle",
                          total_bill > 20 ~ "high")) %>%
  select(bill) %>%
  table()
```
```{r echo=FALSE}
tips %>%
  dplyr::mutate(bill = case_when(total_bill <= 10 ~ "low",
                          total_bill <= 20 ~ "middle",
                          total_bill > 20 ~ "high")) %>%
  dplyr::select(bill) %>%
  table()
```

*Note*: Instead of ` total_bill > 20 ~ "high"` we could use `TRUE ~ "high"`.


### Exercise `r nextExercise()`: Cut variables into groups {.exercise type=A-B answer=A}


Which command is the correct one to cut smokers and dinner time into one group, and the rest of the cases in a different group?

A.  
```{r, eval=FALSE}
tips %>%
  mutate(party = case_when((smoker=="Yes" & time=="Dinner") 
                           ~ "Party",
                           TRUE ~ "No Party"))
```
B.  
```{r, eval=FALSE}
tips %>%
  mutate(party = case_when((smoker=="Yes" | time=="Dinner") 
                           ~ "No Party",
                           TRUE ~ "Party"))
```

::: {.notes}

`smoker=="Yes" & time=="Dinner"`, ie.,  ***A***.

:::

### Summarise variables into one value: `summarise()`

```{r summarise}
tips %>%
  summarise(mean_bill=mean(total_bill), n=n())
```

### Summarise by group: `group_by()`

```{r group_by}
tips %>%
  group_by(sex, time) %>%
  summarise(mean_bill=mean(total_bill), n=n())
```



*NB*: In a similar vein, this procedure may be used to get a balanced/stratified sample: `group_by() %>% sample_n()`


### Exercise `r nextExercise()`: Preparing data {.exercise type=A-B-C-D answer=B}

Mit welchem Befehl können Beobachtungen mit bestimmten Eigenschaften ausgewählt werden?

Which command is needed to filter cases based on some values?

A.  `select()`
B.  `filter()`
C.  `mutate()`
D.  `summarise()`

::: {.notes}

***B*** `filter`

:::



### Get the top $n$ cases: `top_n()`

```{r top_n}
tips %>%
  group_by(sex) %>%
  top_n(n=3, tip) %>% 
  arrange(-tip)
```



### Sort variables (columns): `arrange()`

```{r arrange}
tips %>%
  group_by(sex) %>%
  top_n(n=3, tip) %>%
  arrange(sex)
```



### Merging (joining) data sets ^[Visualization: https://github.com/gadenbuie/tidyexplain] {.shrink}


```{r, eval=FALSE}
# Create ID:
tipsID <- tips %>% mutate(ID=row_number())

# Create two data sets:
tips1 <- tipsID %>% select(ID, total_bill)
tips2 <- tipsID %>% select(ID, tip)

# Match the two data sets:
tips1 %>%
  inner_join(tips2, by = "ID") %>%
  inspect()
```

```{r, echo=FALSE}
# Create ID:
tipsID <- tips %>% mutate(ID=row_number())

# Zwei (Teil-)Datensätze erzeugen
tips1 <- tipsID %>%
  dplyr::select(ID, total_bill)
tips2 <- tipsID %>%
  dplyr::select(ID, tip)

# Innere Verknüpfung
tips1 %>% inner_join(tips2, by = "ID") %>%
  head()
```


### Exercise `r nextExercise()`: Summarize data {.exercise type=essay}


Compute the mean value and the standard deviation of the relative tip amount, conditional on whether it was a "party" or not.

```{r, include=FALSE}
tips %>%
  mutate(party = case_when((smoker=="Yes" & time=="Dinner") ~ "Party",
                           TRUE ~ "No Party"),
         rel_tip=tip/total_bill) %>%
  group_by(party) %>%
  summarise(mean=mean(rel_tip), sd=sd(rel_tip))
```

::: {.notes}
tips %>% mutate(party = case_when((smoker=="Yes" & time=="Dinner") ~ "Party", TRUE ~ "No Party"), rel_tip=tip/total_bill) %>% group_by(party) %>% summarise(mean=mean(rel_tip), sd=sd(rel_tip))
:::


### `mosaic` output as data frames

As per default, output of `mosaic` functions are not given in the form of "tidy" data frames. However, it can be helpful to get the output as a data frame using the function `df_stats^[loaded via `mosaic`] casts the output of some `mosaic` functions into a tidy data frame format:


```{r}
df_stats( tip ~ sex+smoker, data = tips, mean, sd)
```


### More on *tidy* data

*Tidy data*^[[Wickham, H. (2014). Tidy data. Journal of Statistical Software, 59(10), 1-23.](http://dx.doi.org/10.18637/jss.v059.i10)] is rectangular data with



- One variable per column
- One case (observation) per row
- One value per cell

This format is also called *long* format.

*However* we encounter in the wild data sets in *wide* format: One variable spread out across multiple columns.



```{r, eval=FALSE}
# install once:
install.packages("tidyr")
# load package:
library(tidyr)
```
```{r, echo=FALSE}
library(tidyr)
```


### Reshape from *wide* to *long* and back


At times, we have a data set in *wide* format, but we need it in the *long* format (or v.v.):


```{r echo = FALSE}
wide_data <- tibble::tribble(
  ~sales_2018, ~sales_2017, ~sales_2016,  ~...,
         "100",        "101",        "102", "...",
          "90",         "91",         "92", "...",
          "80",         "81",         "82", "...",
           "...",          "...",          "...", "..."
  )


long_data <- tibble::tribble(
  ~sales, ~year,
   "2018", "100",
   "2018",  "90",
   "2018",  "80",
   "2017", "101",
   "2017",  "91",
   "2017",  "81",
   "2016", "102",
      "…",   "…"
  )


```



:::::: {.columns}
::: {.column width="20%"}

matrix in *long* format:

\vspace{1cm}

```{r echo = FALSE}
kable(long_data)
```


:::
::: {.column width="70%"}

matrix in *wide* format:

\vspace{1cm}

```{r echo = FALSE}
kable(wide_data)
```

:::
::::::

Reshaping from *wide* to long* (or v.v.) is called *pivoting*; the functions `pivot_longer()` (cast into long fomat) and `pivot_wider()` (cast into wide format) perform this transformation^[R package `tidyr`].







### Pivot into long format: `pivot_longer()`



Reshapes the data set from wide to long format:^[Install (once) and load the R package `tidyr` for these functions.]


:::::: {.columns}
::: {.column width="60%"}

```{r eval = FALSE}
tips_long <- tips %>% 
  mutate(ID = row_number()) %>% 
  select(ID, sex, smoker, day) %>% 
  pivot_longer(cols = sex:day, 
               names_to = "Variable")
```

:::
::: {.column width="35%"}


```{r echo = FALSE}
tips_long <- tips %>% 
  mutate(ID = row_number()) %>% 
  dplyr::select(ID, sex, smoker, day) %>% 
  pivot_longer(cols = sex:day, 
               names_to = "Variable",
               values_to = "Value")


tips_long %>% 
  head(10) %>% 
knitr::kable()
```


:::
::::::





### Reshape into wide format: `pivot_wider()`


Reshapes the data set from long to wide format:^[Install (once) and load the R package `tidyr` for these functions.]



:::::: {.columns}
::: {.column width="60%"}


```{r eval = FALSE}
tips_wide <- tips_long %>%
  pivot_wider(names_from = "Variable",
              values_from = "Value")

```


:::
::: {.column width="35%"}


:::{.tiny}

```{r echo = FALSE}
tips_wide <- tips_long %>%
  pivot_wider(names_from = "Variable",
              values_from = "Value")

tips_wide %>% 
  head(10) %>% 
  kable()
```
:::
:::
::::::



Check out [this](https://tidyr.tidyverse.org/articles/pivot.html) or [this](https://www.youtube.com/watch?v=D48JHU4llkk) tutorial.


### Exercise `r nextExercise()`: Data preparation {.exercise type=A-B-C answer=A}

Which format of a data set has more rows?

A.  A data set in the long format
B.  A data set in the wide format
C.  Both formats have the same number of rows

::: {.notes}

***A***.

:::






## Missing values


### Check for missing values



Let's make up some missing values (`NAs`):

```{r}
tips_na <- tips
tips_na$tip[c(1,2,3, 42, 244)] <- NA
tips_na$total_bill[c(10, 11, 12)] <- NA
```

```{r}
favstats(~ tip, data = tips_na)
```

Summary data for *each* column:

```{r eval = FALSE}
inspect(tips)
```



### Sources of missing values


Treating missing values depends on the cause of the missing:


1. [Missing completely at random (MCAR)]{.cemph}: eg., *Your dog gobbled up your notes of the participant with the ID `JB007`; it could equally likely have eaten `JB008`.* The missing is not related to the values of the variables of this person (observation).

2. [Missing at random (MAR)]{.cemph}: eg., *Men fail to report their weight more frequently in your suvery compared to women*. The missing values at one varible (weight) are associated with the value of other variables (gender) of a given person.

3. [Not missing at random (NMAR)]{.cemph}: eg., *The lower the weight the more likely that a person fails to report his/her weight*. The probability of some missing value at a variable is associated with the value of this observation at this variable.






### Delete case-wise

Deleting case-wise (whole rows) is an easy remedy. However, a great number of rows may be lost using this procedure.
Ganze Zeilen (ganze Fälle) zu löschen ist eine einfache Methode, um fehlende Werte zu "bereinigen". Beim fallweisen Löschen können aber sehr viele Zeilen verloren gehen.

```{r}
tips_no_na <- na.omit(tips_na)  
```





## Extreme values (outliers) 



### What are outliers?

*Extreme* values or *outliers* are values diverging greatly from the majority of a distribution so that one suspects that they were generated by a different mechanism (different than the mechanisms that generated the majority of the cases).



:::::: {.columns}
::: {.column width="45%"}

```{r echo = FALSE, results = "hide"}

x <- rnorm(1e05)
y <- rnorm(1e04, 0, 1.5)
z <- x + y 

p1 <- gf_dens(~z, color = viridis(2)[1]) %>% 
  gf_dist("norm", color = "grey60") %>% 
  gf_lims(x = c(-5, +5)) %>% 
  gf_vline(xintercept = c(-3,3), linetype = "dashed")

p2 <- gf_boxplot(~z)


xpnorm(q = c(-3, 3), mean = 0, sd = 1.5, verbose = FALSE) %>% 
  gf_theme(legend.position = "none")  


 
```


It is common to classify cases such that $|x_i-\bar{x}| > 3 \cdot s_x$ as outliers, if $X$ is normally distributed.


:::
::: {.column width="45%"}


```{r echo = FALSE}
d <- data.frame(x = 1:10,
                y = 0.7 * 1:10,
                y2 = 0.7 * 1:10)

d$y2[length(d$y)-1] <- d$y[length(d$y)-1] * 0.3


gf_point(y2 ~ x, data = d) %>% 
  gf_refine(scale_x_continuous(breaks = NULL),
            scale_y_continuous(breaks = NULL)) +
  annotate("point", x = length(d$y)-1, y = d$y2[length(d$y2)-1], color = "red", alpha = .7, size = 15) +
  labs(x = "", y = "")
```


A bivariate outlier.

:::
::::::





### Outliers may exert an undue influence


It may be difficult to decide whether a case is an "error" that needs correction (eg., typing error) or whether it is a rare, but valid case (eg., student of age 16). Not much help here.

Outliers may exert a (very/too) high influence of some statistic such as the mean.


```{r echo = FALSE, fig.asp= 0.3}
p1 <- gf_point(y2 ~ x, data = d) %>% 
  gf_lm() %>% 
  gf_lims(y = c(0, 10)) +
  annotate("point", x = length(d$y)-1, y = d$y2[length(d$y2)-1], color = "red", alpha = .7, size = 15) + 
  labs(x= "", y= "")


p2 <- gf_point(y ~ x, data = d) %>% 
  gf_lm() %>% 
  gf_lims(y = c(0, 10)) +
  labs(x= "", y= "")

grid.arrange(p2, p1, nrow = 1)
```




### Identifying outliers using the Boxplot method


According to the Boxplot method, some value $x_i$ is called an outlier if and only if:

$$
x_i < \text{Q1} - 1.5 \cdot \text{IQR} \quad \lor \quad x_i > \text{Q3} + 1.5 \cdot \text{IQR}  
$$



:::::: {.columns}
::: {.column width="30%"}

```{r echo = FALSE, fig.asp= 1}
tips_outlier <- tips %>% 
  filter(tip >=  quantile(~tip, p = .75, data = tips) + 1.5*IQR(~ tip, data = tips))

tips %>% 
  gf_boxplot(tip ~ 1, data = tips) %>% 
  gf_point(tip ~ 1, data = tips_outlier, color = "red", size = 5, alpha = .3) %>% 
  gf_refine(scale_x_continuous(breaks = NULL)) %>% 
  gf_labs(x = "")
```


:::
::: {.column width="70%"}



```{r}
tip_iqr <- IQR(~ tip, data = tips)
tip_q3 <- quantile(~tip, p = .75, data = tips)
tip_q1 <-  quantile(~tip, p = .25, data = tips)

upper <- tip_q3 + 1.5 * tip_iqr
lower <- tip_q1 - 1.5 * tip_iqr

tips_no_outlier <- tips %>% 
filter(tip <  upper | tip > lower)
```


:::
::::::



### Cases with strong influence (I/II)

Cases with strong influence (on a regression model) can be identified by eg., *Cook's D*. Cook's $D_i$ is a measure for the influence of case $i$ on the regression equation.


$$
\text{Cooks D}_i= \frac{\sum ( \hat{y}_i - \hat{y}_{(i)} )^2 } {(k+1) \hat{\sigma}^2_\epsilon}
$$

$D_i$ compares the predicted value of  $\hat{y}_i$ with case $i$ and deleted ($y_{(i)}$) for all cases in the data set. These difference are squared and then summed. The denominator serves to standardize the value.


```{r}
lm1 <- lm(tip ~ total_bill, data = tips)
cooks.distance(lm1) %>% head(3)  # first 3 values
```



### Cases with strong influence (II/II)


Some authors^[z.B. West, West, Cohen & Aiken (2003)] recommend a threshold if $1.0$ as indicative of a influential observation in a regression model.

```{r}
any(cooks.distance(lm1) > 1)
```

In this data set, no observation was influential according to this criterion.

Make sure that your "exciting novel finding" does not hinge on one or two influential points. To remove influential points:

```{r}
tips_no_influential_points <- tips %>% 
  filter(cooks.distance(lm1) < 1)
```













```{r finish-Datenhandling, include=FALSE}
rm(tipsID)
rm(tips1)
rm(tips2)
rm(pathToImages)
# detach("package:tidyr",  unload = TRUE) ## Geht leider nicht!!!
finalizePart()
```
