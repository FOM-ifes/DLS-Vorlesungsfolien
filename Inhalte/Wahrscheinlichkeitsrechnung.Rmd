```{r setup-Wahrscheinlichkeitsrechnung, echo=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Karsten Luebke
#%
# ---------------------------------------------------------------------------
source("../prelude.R")
initPart(
    "Wahrscheinlichkeitsrechnung",  # Dateiname ohne Suffix
    "EinfuehrungInferenz"              # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages = getPathToImages()
# ---------------------------------------------------------------------------

library(mosaic)

tips <- assertData("tips.csv", "https://goo.gl/whKjnl")
```
# Wahrscheinlichkeitsrechnung


### Unsicherheit

Unsicherheit entsteht durch die Möglichkeit von Alternativen:

A.  Wird es morgen regnen?
B.  Wer wird nächste Saison Deutscher Fußballmeister?
C.  Ist die Angeklagte schuldig?
D.  Hilft Lernen beim Klausurerfolg?
E.  Wann wurde Dschingis Khan geboren?
F.  Wenn der Prager Fenstersturz nicht passiert wäre, wäre der 30jährige Krieg dann vermieden worden?
G.  Kann ich beim Mensch-ärgere-Dich-nicht Spiel mit dem nächsten Wurf rauskommen?

Unsicherheit von Aussagen kann also die Vergangenheit, Gegenwart und Zukunft betreffen. Teilweise (*E*) kann sie auch aus Unwissenheit entstehen.

*Wo begegnet Ihnen Unsicherheit?*


### Zufallsexperiment

- Ein Zufallsexperiment ist ein Vorgang bei dem unter (scheinbar) gleichen Voraussetzungen unterschiedliche Ereignisse eintreten können.
- Sei $\omega_i$ (gr.: *omega*) ein einzelnes Elementarereignis (Realisation), z.B. $\omega_i$="Hannover 96" oder $\omega_i$="Der DAX steigt morgen um 5\%", oder $\omega_i$="Die Münze zeigt Kopf".
- $\Omega$ (gr.: *Omega*) ist die Menge aller Elementarereignisse, z.B. $\Omega=\{(\text{"Die Münze zeigt Kopf"}), (\text{"Die Münze zeigt Zahl"})\}$, oder für die Anzahl Kunden $\Omega=\mathbb{N}_0=\{0, 1, 2, \ldots\}$.
- Sei $A$ ein Ereignis, welches aus mehreren Elementarereignissen zusammengesetzt sein kann. z.B. Wurf eines Würfels mit $\Omega=\{\omega_1, \omega_2, \ldots \omega_6\}$ wobei $\omega_i$: "Würfel zeigt $i$" und $A=\{\omega_2, \omega_4, \omega_6\}$. Das gegenteilige Ergeignis (Komplement) ist dann $A^C=\{\omega\subset\Omega: \omega \notin A\}$. 
- $W$ sei unser (Vor-)wissen, z.B. ein fairer, sechs seitiger Würfel. 


### Übung `r nextExercise()`: Ereignis {.exercise type=A-B answer=B}

Wie würden Sie das Ereignis $A^C$ zu $A=\{\omega_2, \omega_4, \omega_6\}$ beim Würfeln beschreiben?

A.  Der Würfel zeigt eine gerade Zahl.
B.  Der Würfel zeigt eine ungerade Zahl.

::: {.notes}

Die Würfelseiten die *nicht* $2,4,6$ sind: $A^C=\{\omega_1, \omega_3, \omega_5\}$, also ungerade, ***B***.

:::


### Notation von Ereignissen

- $\Omega$ ist das sichere Ereignis^[Irgendwas wird passieren...], $\emptyset$ ist das ausgeschlossene Ereignis.
- $A \cup B$ heißt $A$ *oder* $B$ (oder beides): $A \cup B=\{w\in\Omega: \omega \in A \vee \omega \in B\}$^[Vereinigung, $\vee$: logisches *oder*.].
- $A \cap B$ heißt $A$ *und* $B$: $A \cap B=\{w\in\Omega: \omega \in A \wedge \omega \in B\}$^[Durchschnitt, $\wedge$: logisches *und*.].
- $A$ und $B$ heißen *disjunkt*, wenn $A \cap B=\emptyset$ (leere Menge) gilt.
- Beispiel: $A \cap A^C=\emptyset, \quad A\cup A^C=\Omega$.


### Venn-Diagramm

```{r, echo=FALSE, fig.align="center", out.width="45%", results=FALSE}
# https://rstudio-pubs-static.s3.amazonaws.com/13301_6641d73cfac741a59c0a851feb99e98b.html
VennDiagram::draw.triple.venn(100000, 25000, 20000,
                              25000, 10000, 20000, 10000, 
                              category=(c(expression(paste("Alle: ", Omega)), "Hundeliebhaber*in: A", 
                                        "Katzenliebhaber*in: B")),
                              lty = "blank", fill = c("skyblue", "pink1", "mediumorchid"), 
                              cex=2, cat.cex=2)
```

- Es gibt 10000 Hunde- *und* Katzenliebhaber\*innen: $A \cap B$.
- Es gibt 35000 Hunde- *oder* Katzenliebhaber\*innen: $A \cup B$.
- Es gibt 30000, die weder Hunde- noch Katzenliebhaber\*innen sind: $(A \cup B)^C$.


### Wahrscheinlichkeit

Die **Wahrscheinlichkeit** $P$ eines Ereignisses ist ein Maß für die Unsicherheit: $P(A|W)\in[0,1]$, die Wahrscheinlichkeit von $A$, vor unserem Wissenshintergrund $W$. Wenn $W$ *klar* ist, wird es ggfs. nicht angegeben.

Für eine Wahrscheinlichkeit gelten folgende Axiome:

- $0 \leq P(A|W) \leq 1$.
- $P(\Omega|W)=1$.
- $P(A \cup B|W)=P(A|W)+P(B|W)$ wenn $A\cap B=\emptyset$ gilt.


### Übung `r nextExercise()`: Teilmenge {.exercise type=A-B answer=A}

Was gilt, wenn $A$ eine Teilmenge von $B$ ist, d. h., $A\subset B$^[$A \subset B$: $\forall\omega \in A: \omega \in B$ ($\forall$: Für alle.)]?

A.  $P(A|W)\leq P(B|W)$
B.  $P(A|W)\geq P(B|W)$

::: {.notes}
Die Wahrscheinlichkeit einer Teilmenge, z.B. Hundeliebhaber\*innen, kann nicht größer sein als die der Obermenge, z.B. Tierliebhaber\*innen (Lösung ***A***).
:::


### Übung `r nextExercise()`: Komplement {.exercise type=yesno answer=yes}

Stimmt die Aussage: $P(A^C|W)=1-P(A|W)$?

- Ja.
- Nein.

::: {.notes}
***Ja***: $P(A \cup A^C|W)=P(\Omega|W)=1$ und $A \cap A^C=\emptyset$. Damit $1=P(A\cup A^C|W)=P(A|W)+P(A^C|W) \Leftrightarrow P(A^C|W)=1-P(A|W)$
:::


### Übung `r nextExercise()`: Interpretation Wahrscheinlichkeit {.exercise type=A-B-C answer=C}

Welche Alternative beschreibt die Aussage "Die Regenwahrscheinlichkeit für Dortmund liegt morgen bei 10\%" am Besten?

A.  Es wird 10\% der Zeit in Dortmund regnen.
B.  Es wird auf 10\% des Stadtgebietes von Dortmund regnen.
C.  Bei einer Wetterlage und -prognose wie heute, hat es in 10\% der Fälle morgen geregnet.

::: {.notes}
Wahrscheinlichkeiten beziehen sich auf die Unsicherheit bei Zufallsexperimenten. Hier also wie *oft* es in vergleichbaren Situationen geregnet hat, also ***C***. Am Ende des morgigen Tages hat sich unser Wissen $W^N$ geändert, d. h. wir (können) wissen ob es geregnet hat oder nicht, d. h. $P(\text{Regen}|W^N)\in\{0,1\}$.
:::


### Cartoon: Wahrscheinlichkeit

```{r echo=FALSE, out.width = "30%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2016/Caption-Contest_07-2016.jpg", "cartoon0716.jpg", pathToImages)
```

"Na, das nenne ich mal eine 25\% Chance für gutes Wetter!"^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/july/2016/results) &copy; J.B. Landers, Überschrift M. Huberty]


### Bedingte Wahrscheinlichkeit

- Die bedingte Wahrscheinlichkeit von $A$ gegeben $B$, d. h., von $A$ unter der Bedingung $B$, ist die Wahrscheinlichkeit von $A$, wenn wir wissen, dass $B$ eingetreten ist: $$P(A|B,W)=\frac{P(A\cap B|W)}{P(B|W)}$$
- Umgestellt: $$P(A\cap B|W)=P(A|B,W)\cdot{P(B|W)}$$.

Sei $W$ ein fairer, sechseitiger Würfel mit $\Omega=\{\omega_1, \omega_2, \ldots \omega_6\}$: Mit $B=\{\omega_2, \omega_4,\omega_6\}$ und $A=\{\omega_2\}$ gilt $P(A|B,W)=\frac{\frac{1}{6}}{\frac{1}{2}}=\frac{1}{3}$ Wenn der Würfel eine gerade Zahl zeigt, ist dies in einem von drei Fällen eine $2$.


### Übung `r nextExercise()`: Bedingte Wahrscheinlichkeit {.exercise type=A-B-C answer=C}

Was gilt für die bedingte Wahrscheinlichkeit?

A.  $P(A|B,W) \leq P(A|W)$
B.  $P(A|B,W) \geq P(A|W)$
C.  Keine pauschale Aussage möglich.

::: {.notes}
***C***: Die bedingte Wahrscheinlichkeit kann kleiner, größer oder gleich der unbedingten sein: Die Wahrscheinlichkeit eine $3$ zu würfeln ist kleiner als die unbedingte, wenn ich weiß dass eine gerade Zahl gewürfelt wurde, sie ist größer als die unbedingte, wenn ich weiß dass eine ungerade Zahl gewürfelt wurde. Sie ist unverändert, wenn sich $B$ z.B. auf den vorherigen Wurf bezieht -- wenn die Würfe *unabhängig* sind.
:::


### Unabhängigkeit

- Zwei Ereignisse sind **unabhängig**, wenn gilt: $$P(A \cap B|W)=P(A|W)\cdot P(B|W)$$
- Wenn zwei Ereignisse unabhängig sind, gilt: $$P(A|B,W)=P(A|W), \quad P(B|A,W)=P(B|W)$$ D. h., dadurch, dass ein Ereignis eingetreten ist, ändert sich *nicht* die Wahrscheinlichkeit des anderen.^[Eine harte Forderung: Wenn in China ein Sack Reis umfällt...]


### Übung `r nextExercise()`: Unabhängigkeit {.exercise type=A-B-C-D answer=A}

Welche Ereignisse sind vermutlich unabhängig?

A.  Wiederholtes Werfen einer fairen Münze.
B.  Größe und Gewicht einer Person.
C.  Lernen und Klausurerfolg.
D.  Bildungsabschluss und Gehalt.

::: {.notes}
Tendenziell sind große Menschen schwerer, daher nicht B. Häufig ohne Lernen kein Klausurerfolg, daher nicht C. Es zeigt sich (*Tipp:* Recherschieren Sie dies nach!), dass Personen mit höheren Bildungsabschlüssen tendenziell höhere Gehälter erzielen können, daher nicht *D*. Wiederholtes Werfen einer fairen Münze sollte aber unabhängig sein, also ***A***.
:::


### Cartoon: Unabhängigkeit

```{r echo=FALSE, out.width = "40%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2018/Caption-Contest_08-2018.jpg", "cartoon0818.jpg", pathToImages)
```

"Nachdem Sie am selben Tag das Lotto 6 aus 49 und den Eurojackpot gewannen gingen Hans und Peter feiern."^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/august/2018/results) &copy; J.B. Landers, Überschrift Michael Albers (Übersetzung/ Anpassung KL)]


### Das Gesetz der großen Zahl

Wenn ein Zufallsexperiment beliebig oft wiederholt werden kann^[z.B. beim (wiederholten) Glücksspiel], dann nähert sich die *empirische* Wahrscheinlichkeit^[d. h. die relative Häufigkeit des Ereignisses] der *theoretischen* Wahrscheinlichkeit^[z.B. bestimmbar, wenn alle Elementarereignisse die gleiche Wahrscheinlichkeit haben] an.

```{r, fig.align="center", out.width="60%", echo=FALSE}
set.seed(1896)
muenz <- rflip(500)
anteil_kopf <- cumsum(attr(muenz, which="sequence")=="H")/1:length(attr(muenz, which="sequence"))
plot(anteil_kopf, col=trellis.par.get("plot.line")$col, lwd=2, ylab="Anteil Kopf", xlab="Würfe", cex=2, main="Wurf einer fairen Münze", ylim=c(0,1), type="l")
```


### Übung `r nextExercise()`: Ziegenproblem {.exercise type=A-B-C answer=A}

> Nehmen Sie an, Sie wären in einer Spielshow und hätten die Wahl zwischen drei Toren. Hinter einem der Tore ist ein Auto, hinter den anderen sind Ziegen. Sie wählen ein Tor, sagen wir, Tor Nummer 1, und der Showmaster, der weiß, was hinter den Toren ist, öffnet ein anderes Tor, sagen wir, Nummer 3, hinter dem eine Ziege steht. Er fragt Sie nun: "Möchten Sie das Tor Nummer 2?"" Ist es von Vorteil, die Wahl des Tores zu ändern?^[Craig F. Whitaker: Ask Marilyn.  Parade Magazine, 9. September 1990, S. 16.]

A.  Ja, wechseln erhöht die Gewinnwahrscheinlichkeit.
B.  Nein, wechseln senkt die Gewinnwahrscheinlichkeit.
C.  Es ist egal ob ich wechsel.

::: {.notes}
***A***: Angenommen Sie spielen das Spiel 999 mal. Dann können Sie *erwarten*, dass Sie in ca. 333 der Fälle zu Beginn richtig lagen, in 666 aber falsch. D. h. durch den Wechsel verdoppeln Sie die Gewinnwahrscheinlichkeit.

Für jemanden, der erst kommt, nachdem die Tür geöffnet wurde und der nicht weiß, auf welche Tür Sie gezeigt haben, für den ist es in der Tat egal - aber der hat ein anderes Wissen ($W'$).

*Verwirrt*? Sie sind in wunderbarer Gesellschaft. 

P.S. Das Problem ist auch unter dem Namen *Monty-Hall-Problem* bekannt.
:::


### Totale Wahrscheinlichkeit

5\% der Bauteile von Lieferant "Gut und teuer" sind defekt, 20\% der Bauteile von "Schnell und billig". Sie bekommen 90\% der Bauteile von "Schnell und billig" ($W$). Wie groß ist die Wahrscheinlichkeit, dass ein Bauteil defekt ist.

- Angenommen Sie bekommen 10000 Teile. Dann sind $9000=10000\cdot 0,9$ von "Schnell und billig", $1000=10000\cdot (1-0,9)$ von "Gut und teuer".
- Von den $9000$ "Schnell und billig" sind $9000\cdot 0,2=1800$ defekt, von den $1000$ "Gut und teuer" sind es $1000\cdot 0,05=50$. Macht zusammen $1800+50=1850$ von $10000$, also $P(\text{Defekt}|W)=\frac{1850}{10000}=0,185$: Man kann also aus den bedingten Einzelwahrscheinlichkeiten die Gesamtwahrscheinlichkeit berechnen: **Satz von der totalen Wahrscheinlichkeit**^[Funktioniert analog für mehrere Ereignisse $B_i$ mit $\Omega =\cup_i B_i$ mit $B_i \cap B_j=\emptyset \forall i \neq j$.]
$$P(A|W)=P(A|B,W) \cdot P(B|W) + P(A|B^C,W) \cdot P(B^C|W)$$


### Übung `r nextExercise()`: Totale Wahrscheinlichkeit {.exercise type=A-B-C-D answer=C}

Wofür steht das $A$ im Beispiel zur totalen Wahrscheinlichkeit?

A.  Dafür, dass ein Bauteil von "Gut und teuer" kommt.
B.  Dafür, dass ein Bauteil von "Schnell und billig" kommt.
C.  Dafür, dass ein Bauteil defekt ist.
D.  Dafür, dass ein Bauteil nicht defekt ist.

::: {.notes}
*Ziel* der Berechnung war es, herauszufinden, ob ein Bauteil defekt ist, also $A=\text{Bauteil defekt}$ (***C***). In dem Fall wäre  $A^C=\text{Bauteil nicht defekt}$. Das Ereignis $B$ kann $B_1=\text{Bauteil von "Schnell und Billig"}$ sein, dann wäre $B_1^C=\text{Bauteil nicht von "Schnell und Billig"}=\text{Bauteil von "Gut und teuer"}$ (wie im Beispiel) *oder* analog könnte $B_2=\text{Bauteil von "Gut und teuer"}$ sein, dann wäre $B_2^C=\text{Bauteil nicht von "Gut und teuer"}=\text{Bauteil von "Schnell und Billig"}$
:::


### Übung `r nextExercise()`: Gegenwahrscheinlichkeit {.exercise type=A-B-C-D-E answer=E}

Wie groß ist im Beispiel $P(A^C|W)$?

A.  $P(A^C|W)=0,8$
B.  $P(A^C|W)=0,2$
C.  $P(A^C|W)=0,05$
D.  $P(A^C|W)=0,185$
E.  $P(A^C|W)=0,815$

::: {.notes}
Es gilt $A=\text{Bauteil defekt}$ und damit $P(A|W)=0,185$. Damit gilt $P(A^C|W)=1-P(A|W)=1-0,185=0,815$, also ***E***.
:::


### Satz von Bayes

$$P(A|B,W)=\frac{P(B|A,W)\cdot P(A|W)}{P(B|W)}$$

- $P(A|B,W)$: Bedingte Wahrscheinlichkeit von $A$ gegeben $B$.
- $P(B|A,W)$: Bedingte Wahrscheinlichkeit von $B$ gegeben $A$.
- $P(A|W), P(B|W)$: Unbedingte Wahrscheinlichkeit^[auch marginale Wahrscheinlickeit.] von $A$ bzw. $B$.

Mit Hilfe des **Satzes von Bayes** können Sie die *Bedingungen umkehren*!

*Tipp*: Statt mit Wahrscheinlichkeiten absolute Häufigkeiten verwenden.


### Spambeispiel (I/II)

- $A$: eine Spam-Email, $A^C$: keine Spam-Email.
- $B$: das Wort "Viagra" in der Email, $B^C$: das Wort "Viagra" nicht in der Email.
- $P(B|A,W)=0,5$, d. h., 50\% der Spamemails enthalten das Wort "Viagra", $P(B|A^C,W)=0,001$, d. h. nur eine von 1000 Nicht-Spam Emails enthält das Wort "Viagra".
- $P(A|W)=0,2$, d. h., die unbedingte Wahrscheinlichkeit für Spam liegt bei 20\% (*A priori*). 
- Gesucht: $P(A|B,W)$, d. h. die Wahrscheinlichkeit, dass es sich um Spam handelt, wenn das Wort "Viagra" in der Email vorkommt (*A posteriori*).


### Spambeispiel (II/II)

1.  Bestimmung der Wahrscheinlichkeit, dass das Wort "Viagra" in einer Email ist: Satz von der totalen Wahrscheinlichkeit:
$$\begin{aligned} 
P(B|W) &= P(B|A,W)\cdot P(A|W) + P(B|A^C,W)\cdot P(A^C|W) \\
&= 0,5 \cdot 0,2 + 0,001 \cdot (1-0,2) \\
&= 0,10008
\end{aligned}$$

2.  Bestimmung der Wahrscheinlichkeit, dass es sich um eine Spam-Email handelt, wenn das Wort "Viagra" in einer Email ist: Satz von Bayes:
$$\begin{aligned} 
P(A|B,W)&=\frac{P(B|A,W)\cdot P(A|W)}{P(B|W)} \\
&= \frac{0,5 \cdot 0,2}{0,10008} \\
&= 0,9992006
\end{aligned}$$

Die Wahrscheinlichkeit, dass es sich bei der Email mit dem Wort "Viagra" um Spam handelt liegt bei über 99,9\%!


### Übung `r nextExercise()`: Satz von Bayes {.exercise type=A-B-C-D answer=D}

Ein Test schlägt immer Alarm, wenn ein Fall, z. B. Krankheit, vorliegt, und es gibt nur in 5\% der Fälle einen Fehlalarm. *A priori* ist einer von 1000 ein Fall, d. h. z. B. krank. Wie hoch ist die Wahrscheinlichkeit, dass ein Fall, d. h. z. B. Krankheit, vorliegt, wenn ein Alarm erfolgt?

A.  $\approx 100\%$
B.  $\approx 95\%$
C.  $\approx 50\%$
D.  $\approx 2\%$

::: {.notes}
Es gibt bei 1000 Personen ca. $\approx 51 \times$ Alarm: den einen, der mit Sicherheit erkannt wird plus die $\approx 50$ Fehlalarme ($999\cdot(1-0,95)$). Von diesen $\approx 51$ ist nur einer *echt*, also $P(\text{Fall}|\text{Alarm},W) \approx \frac{1}{51}\approx 0,02$, damit ***D***.
:::


### Offene Übung `r nextExercise()`: Risk Literacy {.exercise type=essay}

Bitte nehmen Sie an folgendem Test teil:

[http://www.riskliteracy.org/](http://www.riskliteracy.org/)

::: {.notes}
*Individuell*
:::


### Sensitivität (True positive) und Spezifität (True negative)

- **Sensitivität**: Anteil der richtig positiven Testergebnisse, z.B. Krankheit korrekt erkannt (True positive).^[False positive sind diejenigen, die als krank diagnostiziert werden, es aber nicht sind.]
- **Spezifität**: Anteil der richtig negativen Testergebnisse, z.B. Gesundheit korrekt erkannt (True negative).^[False negative sind diejenigen, die als gesund diagnostiziert werden, es aber nicht sind.]
- **Prävalenz**: Anteil der an einem Stichtag erkrankten Personen.


### Übung `r nextExercise()`: Sensitivität {.exercise type=A-B answer=A}

Was bedeutet die Aussage: "Der Test hat eine Sensitivität von 95\%"?

A.  Von 100 Kranken werden 5 fälschlicherweise als gesund eingestuft.
B.  Von 100 Gesunden werden 5 fälschlicherweise als krank eingestuft.

::: {.notes}
Sensitivität gibt an, wie oft, bei vorhandener Krankheit, diese korrekt erkannt wird. Hier werden von 100 Kranken 95 richtig erkannt bleiben 5 übrig, daher ***A***. B wäre richtig, wenn die *Spezifität* ebenfalls bei 95% liegen würde.

Ein guter Test hat eine hohe Sensitivität und eine hohe Spezifität, häufig muss man aber einen Kompromiss finden - vgl. Receiver-Operating-Characteristic-Kurve (ROC).
:::


### Odds und Odds Ratio

Angenommen in einem Kurs sitzen 100 Studierende, 90 arbeiten mit, 10 nicht. Von den 90, die mitarbeiten, bestehen 80 die Klausur, von den 10, die nicht mitarbeiten, 1.^[Rein fiktive Zahlen!]

- Die **Chance** (engl. *odds*) die Klausur zu bestehen, wenn mitgearbeitet wird, liegt bei $80:10=8$ $$Odds(A|B,W)=\frac{P(A|B,W)}{1-P(A|B,W)}$$.
- Die Chance zu bestehen, wenn nicht mitarbeitet wird, liegt bei $1:9$.
- Das **Chancenverhältnis** (Quotenverhältnis, engl. *odds ratio*, $OR$), liegt bei $8:\frac{1}{9}=72$ - d. h. die Chance die Klausur zu bestehen ist 72 mal höher, wenn mitgearbeitet wird als wenn nicht mitgearbeitet wird.
$$OddsRatio=\frac{Odds(A|B,W)}{Odds(A|B^C,W)}=\frac{P(A|B,W)\cdot(1-P(A|B^C,W)}{P(A|B^C,W)\cdot(1-P(A|B,W)}$$


### Odds Ratio aus Vierfeldertafel

+-----------------------+---------------------+--------------------+--------------+
|                       | **Test positiv**    | **Test negativ**   | **Summe**    |
+=======================+=====================+====================+==============+
| **Realität positiv**  | $n_{11}$            | $n_{12}$           | $n_{1\cdot}$ |
+-----------------------+---------------------+--------------------+--------------+
| **Realität negativ**  | $n_{21}$            | $n_{22}$           | $n_{2\cdot}$ |                 
+-----------------------+---------------------+--------------------+--------------+
| **Summe**              | $n_{\cdot 1}$      | $n_{\cdot 2}$      | $n$          |
+-----------------------+---------------------+--------------------+--------------+

$$OddsRatio=\frac{\frac{n_{11}}{n_{21}}}{\frac{n_{12}}{n_{22}}}$$

- Sensitivität^[True positive rate, TPR]: $\frac{n_{11}}{n_{1 \cdot}}$
- Spezifität^[True negative rate, TNR]: $\frac{n_{22}}{n_{2 \cdot}}$


### Offene Übung `r nextExercise()`: Gesichtserkennung {.exercise type=essay}

Angenommen 1\% der Bevölkerung sind (schwere) Straftäter\*innen. Eine Gesichterkennungssoftware erkennt mit 70\% Genauigkeit  
Straftäter\*innen wieder, und nur in 1\% der Fälle wird jemand fälschlich verdächtigt^[[https://www.bmi.bund.de/SharedDocs/kurzmeldungen/DE/2017/12/sicherheitsbahnhof-verlaengerung.html](https://www.bmi.bund.de/SharedDocs/kurzmeldungen/DE/2017/12/sicherheitsbahnhof-verlaengerung.html)]. Gehen Sie von einer Besucheranzahl von 100000 Personen aus. Füllen Sie bitte die Vierfeldertafel.

+-----------------------+--------------------------+--------------------------+---------------+
|                       | **Gesichtserkennung** \  | **Gesichtserkennung** \  | **Summe**     |
|                       | **Alarm**                | **kein Alarm**           |               |
+=======================+==========================+==========================+===============+
| **Straftäter\*in** \  | $n_{11}=$                | $n_{12}=$                | $n_{1\cdot}=$ |
|                       |                          |                          |               | 
+-----------------------+--------------------------+--------------------------+---------------+
| **kein(e)**\          | $n_{21}=$                | $n_{22}=$                | $n_{2\cdot}=$ |  
| **Straftäter\*in**    |                          |                          |               |       
+-----------------------+--------------------------+--------------------------+---------------+
| **Summe** \           | $n_{\cdot 1}=$           | $n_{\cdot 2}=$           | $n=100000$    |
|                       |                          |                          |               | 
+-----------------------+--------------------------+--------------------------+---------------+

::: {.notes}

+-----------------------+--------------------------+--------------------------+--------------------+
|                       | **Gesichtserkennung** \  | **Gesichtserkennung** \  | **Summe**          |
|                       | **Alarm**                | **kein Alarm**           |                    |
+=======================+==========================+==========================+====================+
| **Straftäter\*in** \  | $n_{11}=700$             | $n_{12}=300$             | $n_{1\cdot}=1000$  |
|                       |                          |                          |                    | 
+-----------------------+--------------------------+--------------------------+--------------------+
| **kein(e)**\          | $n_{21}=990$             | $n_{22}=98010$           | $n_{2\cdot}=99000$ |  
| **Straftäter\*in**    |                          |                          |                    |       
+-----------------------+--------------------------+--------------------------+--------------------+
| **Summe** \           | $n_{\cdot 1}=1690$       | $n_{\cdot 2}=98310$      | $n=100000$         |
|                       |                          |                          |                    | 
+-----------------------+--------------------------+--------------------------+--------------------+

:::


### Offene Übung `r nextExercise()`: Präzision Gesichtserkennung {.exercise type=essay}

Wie hoch ist der Anteil der richtig erkannten Straftäter\*innen, d. h. wie viele der Alarme sind berechtigt, d. h. *a posteriori* Wahrscheinlichkeit ein(e) Straftäter\*in zu sein, wenn ein Alarm vorliegt?

::: {.notes}

$$\frac{n_{11}}{n_{\cdot 1}}=\frac{700}{1690}\approx 0,41$$
D. h., die Wahrscheinlichkeit *wirklich* ein(e) Straftäter\*in gefunden zu haben ist kleiner als $0,5$. Für jede konkrete Person gilt aber, dass er/sie entweder ein Straftäter\*in ist - oder nicht. Auf lange Sicht, d. h. bei wiederholter Anwendung, erwarten wir, dass $\approx 41\%$ der von der Gesichtserkennung vermuteten Personen wirklich Straftäter\*in sind.
In der Pressemitteilung [https://www.bmi.bund.de/SharedDocs/kurzmeldungen/DE/2017/12/sicherheitsbahnhof-verlaengerung.html](https://www.bmi.bund.de/SharedDocs/kurzmeldungen/DE/2017/12/sicherheitsbahnhof-verlaengerung.html) sind die genauen Zahlen nicht angegeben, und technischer Fortschritt sollte die Präzision erhöhen können.

:::


### Offene Übung `r nextExercise()`: Odds Ratio Gesichtserkennung {.exercise type=essay}

Wie ändert sich die Chance ein(e) Straftäter\*in zu sein, wenn ein Alarm vorliegt?

::: {.notes}

$$OddsRatio=\frac{\frac{n_{11}}{n_{21}}}{\frac{n_{12}}{n_{22}}}=\frac{\frac{700}{990}}{\frac{300}{98010}}=231$$
D. h., die Chance eine(n) Straftäter\*in vor sich zu haben ist 231 mal so hoch, wenn die Gesichterkennung Alarm gegegeben hat, als wenn sie es nicht getan hat.
:::

```{r finish-Wahrscheinlichkeitsrechnung, include=FALSE}
rm(pathToImages)
finalizePart(partname)
```
