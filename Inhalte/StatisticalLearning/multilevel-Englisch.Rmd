
```{r setup-Multilevel, include=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Norman Markgraf
#%
# ---------------------------------------------------------------------------
source("../../prelude.R")
initPart(
    "multilevel",  # Dateiname ohne Suffix
    "StatisticalLearning"      # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages = getPathToImages()
# ---------------------------------------------------------------------------


options(tinytex.verbose = TRUE)
```





```{r libs-multilevel, include = FALSE}
library(mosaic)
library(tidyverse)
library(latex2exp)
library("multipanelfigure")
library(lme4)
library(arm)
library(broom)
```




# Multi level modelling


## Basics


### Exercise `r nextExercise()`: A statistician in a café {.exercise type=A-B-C-D answer=C}



:::::: {.columns}
::: {.column width="70%"}

A statistician goes to a bar (in Paris) and orders a tea (camomile). It's his first time in a café. He only has a vague idea about waiting time which he summarizes so: $W \sim \text{N}(\mu=5, \sigma=1)$. Four minutes later, his tea is served. Hmm, delicious, fine camomile.

Later on, when he comes to some other café, he asks himself "what waiting should I expect?"


A.  5 Minutes
B.  4 Minutes
C.  somewhere between 4 and 5 minutes
D.  half an hour; Frankonians are laid back (the café happens to be in Nuremberg)

:::
::: {.column width="20%"}

"No thing better than a fine tea!"

```{r, echo = FALSE, out.width="70%"} 
knitr::include_graphics(file.path(pathToImages, "Youngronaldfisher2.jpeg"))
```

:::{.tiny}
Sir Ronald Fisher at young age, [Source](https://en.wikipedia.org/wiki/Ronald_Fisher), Licnce: Public Domain
:::

:::
::::::



::: {.notes}
***C***. It makes sense to consider previous experiences (first café). However, we cannot assume that the second café equals the first. Hence, a mixture (as in café melange) serves the purpose well.


:::




### Statistics with amnesia


Typical stastistical models suffer from amnesia. A manual for doing statsistics with amnesia:

\vspace{1.5cm}


:::::: {.columns}
::: {.column width="50%"}

[Complete Pooling]{.cemph}

- Don't differentiate between cafés.
- Compute the average waiting times across all cafés (including Frankonia)
- *Problem*: Nuremberg is not Paris.


:::
::: {.column width="50%"}

[No Pooling]{.cemph}

- Compute the waiting time for each café separately.
- In Paris consider only the Paris waiting times, but not Nuremberg etc.
- *Problem*: I have abounding experience for Nuremberg, but scarcely for Paris. How to include this disbalance? In addition, what about London or Adelaide?

:::
::::::


### Multi level models^[Confusing terminology: hierarchical-, random effects -, mixed effects models etc. ] *do* have a memory

:::::: {.columns}
::: {.column width="50%"}

It helps to differentiate between

- a distribution of waiting times in the population of cafés
- a distribution for each café
  (and possibly a distribution for cities, but let's keep things simple)

Having learnt something about waiting times in some café, we update

- the distribution of waiting times in the café-population
- the distribution of waiting times in the present café

:::
::: {.column width="50%"}

```{r out.width="90%", fig.asp = 1, echo = FALSE}
theme_set(
  theme.fom  
)

p1 <-  gf_dist("norm", params = list(mean = 5, sd = 1)) %>% 
  gf_labs(title = "All cafés", y = "", x = "") %>% 
  gf_refine(scale_y_continuous(breaks = NULL)) +
  annotate(geom = "label", x = 5, y = 0.1,
           label = TeX("$\\mu = 5, \\sigma = 1$"),
           vjust = "top")

p_Paris <- gf_dist("norm", params = list(mean = 4, sd = .3)) %>% 
  gf_labs(title = "Cafés parisienne", y = "", x = "") %>% 
  gf_refine(scale_y_continuous(breaks = NULL)) +
    annotate(geom = "label", x = 4, y = 0.1,
           label = TeX("$\\mu = 4, \\sigma = .3$"),
           vjust = "top")


p_Nuernberg <- gf_dist("norm", params = list(mean = 30, sd = 3)) %>% 
  gf_labs(title = "Cafés in Nuremberg", y = "", x = "") %>% 
  gf_refine(scale_y_continuous(breaks = NULL)) +
  annotate(geom = "label", x = 30, y = 0.1,
           label = TeX("$\\mu = 30, \\sigma = 3$"),
           vjust = "top")

#p_etc <- ggplot() + geom_emoji("white_circle", color='grey40') + theme_void()

p_dots <- ggplot() + annotate(geom = "label", x = 0, y = 0,
                               label = "etc.", size = 18) + theme_void()

figure1 <- multi_panel_figure(rows = 2, columns = 3) %>% 
  fill_panel(p1, row = 1, column = 1:3) %>% 
  fill_panel(p_Paris, row = 2, column = 1) %>% 
  fill_panel(p_Nuernberg, row = 2, column = 2) %>% 
  fill_panel(p_dots, row = 2, column = 3)
figure1
```

:::
::::::


### Multi level models - what's that?

[Multi level models]{.cemph} are *regression models* that ...

- can be seen as generalization of the standard linear (and of the GLM)
- where parameters are computed for each group (café) and for the population of these groups
- where the group parameters are being estimated by use of a population model
- observational units may be nested within each other eg.,



:::::: {.columns}
::: {.column width="30%"}

- countries in states (level 3)
- states in districts (level 2)
- districts in counties (level 1)

  
:::
::: {.column width="30%"}

- schools in classes (level 2)
- classes in pupils (level 1)


:::
::: {.column width="30%"}

- corporations in departments (l3)
- departments in teams (l2)
- teams in individuals (l1)


:::
::::::


### Pros and cons of multi level models


>    When it comes to regression, multilevel regression deservers to be the default approach. (McElreath, 2016, S. 356) ([Dr. Dogg, should I use multi level modelling?](http://elevanth.org/blog/2017/08/24/multilevel-regression-as-default/))


:::::: {.columns}
::: {.column width="50%"}

[Pro]{.cemph}

- More precise estimation of parameters
- Group size differences influences parameter estimation
- Variation between groups is explicitly modelled
- No aggregation needed
- flexible methodology
- Prediction for new groups possible (eg., cafés in Dortmund)

:::
::: {.column width="50%"}

[Contra]{.cemph}

- More assumptions including model specifications on level 2
- Estimation more complex
- Interpretation more complex
- If the number of level 2 units is small ($<5$), results tend to converge to standard regression


:::
::::::





### Shrinkage 

```{r echo = FALSE, out.width="70%", fig.asp = .5 }
knitr::include_graphics(file.path(pathToImages, "p-radon.pdf"))
```

Multi level model shrink the coefficients towards the mean of the groups (cafés). The smaller the sample, the stronger the shrinkage.





### Types of multi level models


```{r echo=FALSE, out.width = "70%", warnings="FALSE"}
n <- 20
b <- 1
a <- 0
Sigma <- matrix(c(1, 0, 0, 1), nrow = 2) * 0.5
slopes <- mvtnorm::rmvnorm(n, c(a, b), Sigma)  %>%
  as_tibble() %>%
  set_names(c("intercept", "slope"))
bind_rows(
  mutate(slopes, x = -2,
         xend = 2,
         y = a + b * x,
         yend = a + b * xend,
         type = "No-pooling"),
  mutate(slopes, x = -2,
         xend = 2,
         y = intercept + b * x,
         yend = intercept + b * xend,
         type = "Varying intercept"),
  mutate(slopes, x = -2,
         xend = 2,
         y = a + slope * x,
         yend = a + slope * xend,
         type = "Varying Slopes"),
  mutate(slopes,
         x = -2,
         xend = 2,
         y = intercept + slope * x,
         yend = intercept + slope * xend,
         type = "Varying slope and intercept")
) %>%
  ggplot(aes(x = x, xend = xend, y = y, yend = yend)) +
  geom_segment() +
  facet_wrap(~ type, ncol = 2) +
  theme_void()
```






## Case study: Radon radiation



### What's the problem with Radon?^[Vgl. Gelmann & Hill, 2007, Kap. 12]

Radon is a chemical radioactive element, and colorless and odorless. Its concentration varies according to local differences in geology. Studies have shown a link between radon exposure (inhaling) and lung cancer. It has been estimated that approx. 5% of lung cancer cases in Germany have been caused by Radon^[http://www.bfs.de/DE/themen/ion/umwelt/radon/wirkungen/wirkungen.html]. 

In a study, the Radon level in 919 houses in 85 counties of the USA have been measure (in Picocuries $pCi$, which is about $10^3$ radioactive decay chains per litre air in  24 hours^[https://sosradon.org/Radon%20Basics]). In addition, it was noted whether the measurement was performed at basement or soil level. Unit of observation is a house.


Load data (package need to be installed):

```{r}
data("radon", package = "rstanarm")
```



### Variability of Radon levels in total




:::{.tiny}
```{r}
favstats(~ log_radon, data = radon)
```
:::



:::::: {.columns}
::: {.column width="50%"}


```{r echo = FALSE, eval = TRUE}
radon %>% head() %>%
  mutate_if(is.numeric, round, 2) %>%
  knitr::kable(booktabs = TRUE)
```


:::
::: {.column width="45%"}


```{r out.width="50%"}
gf_histogram(~log_radon, 
             data = radon)
```

:::
::::::



### Variability of Radon levels cross counties



:::::: {.columns}
::: {.column width="50%"}

:::{.small}
```{r}
radon_county <- radon %>% 
  group_by(county) %>% 
  summarise(log_radon_avg = 
              mean(log_radon),
            log_radon_sd = 
              sd(log_radon)) 

radon_county %>% head(3)
```
:::

:::
::: {.column width="45%"}

:::{.tiny}
```{r}
gf_histogram( ~ log_radon_avg, 
              data = radon_county) %>% 
  gf_vline(xintercept = 
             mean(radon_county$log_radon_avg))
```
:::
:::
::::::


### Is the Radon level correlated with the sample size?


:::::: {.columns}
::: {.column width="60%"}
```{r}
radon_sum <- radon %>% 
  group_by(county) %>% 
  summarise(n_county = n(),
            radon_mean_county = 
              mean(log_radon))

radon_sum %>% 
  summarise(r = cor(n_county, 
                radon_mean_county))
```


:::
::: {.column width="40%"}

```{r echo = FALSE}
gf_point(radon_mean_county ~ n_county, data = radon_sum)

```

Small samples -- high Radon levels?

True effect or statistical artifact?



:::
::::::


### Complete pooling model


```{r}
library(broom)
radon_complete_pooling <- lm(log_radon ~ 1, data = radon)
tidy(radon_complete_pooling)
```

$SD$ of the residuals:

```{r}
radon_complete_pooling$residuals %>% sd()
```


### No pooling modell 


```{r}
radon_no_pooling <- lm(log_radon ~ county - 1, data = radon)

tidy(radon_no_pooling) %>% head(3)
```


Numbers of coefficients:

```{r}
coef(radon_no_pooling) %>% length()
```







### Partial pooling model (multi level model)

Model definition:

$$
\begin{aligned}
y_i &\sim \text{N}(\mu_i, \sigma_y)\\
\mu_i &= \alpha_{j[i]} \\
\alpha_j &\sim \text{N}(\mu_a, \sigma_a)
\end{aligned}
$$

$\mu_a$ and $\sigma_a$ are estimated from the data.

```{r radon-ml1}
radon_ml1 <- lme4::lmer(log_radon ~ (1|county), data = radon)
```


`(1|county)`:  `1` indicates the intercept which is allowed to vary between counties.

The distribution of intercepts is being estimated in a multi level model.





### Results for "fixed" effects

Effects *not* specified by the model are called *fixed effects*. No distribution is estimated for fixed effects.


```{r results = "hold"}
library(broom.mixed)
tidy(radon_ml1)
```

The average Radon level ($\mu_a$) is estimated at `r round(fixef(radon_ml1), 2)` with a SE of `r round(se.fixef(radon_ml1), 2)` .


### Results for "random" effects

Effects specified by the model are called *random effects*. A distribution is estimated for random effects.



```{r}
tidy(radon_ml1)
```

The variablity of the counties ($\sigma_a = 0.30$) is smaller than the variability of individual house ($\sigma_y = 0.77$).



### Results on county level


```{r}
augment(radon_ml1) %>% head(5) %>% dplyr::select(2,3,4,5,9)
```


Eg., county Aitkin: $y = \alpha_1 = 1.11$; for the first two house in Aitkin the same log Radon level was measured.



### 95% confidence intervals

*fixed* effect -- Intercept of county population ($\mu_a$):
```{r}
library(arm)
fixef(radon_ml1) + c(-2,2)*se.fixef(radon_ml1)
```


*random* Effect  (multi level effect) -- Intercept of each county ($\alpha_j$):


eg., for county 42 of a total of `r length(ranef(radon_ml1)$county[, 1])`:


```{r}
ranef(radon_ml1)$county[42, 1] + 
  c(-2,2)*se.ranef(radon_ml1)$county[42, 1]
```



### Estimates and their SEs

Comparing the no-pooling-model and the multi level model:


:::{.small}
```{r echo = TRUE}
radon2 <- data_frame(
  county_idx = 1:85,
  county = radon_sum$county,
  n_county = radon_sum$n_county,
  radon_avg_county_nopool = coef(radon_no_pooling),
  radon_avg_county_nopool_se = se.coef(radon_no_pooling),
  radon_avg_county_ml = coef(radon_ml1)$county[, 1],
  radon_avg_county_ml_se = se.ranef(radon_ml1)$county[, 1]
)
```

```{r echo = FALSE}
radon2 %>% glimpse()
```

:::

### Precision of estimation as a function of sample size


```{r echo = FALSE}
radon2_long <- radon2 %>% 
  pivot_longer(cols = c(radon_avg_county_nopool, radon_avg_county_ml),
               names_to = "model", values_to = "estimate") %>% 
  pivot_longer(cols = c(radon_avg_county_nopool_se, radon_avg_county_ml_se),
             names_to = "model_se", values_to = "SE" )


radon2_long <- radon2_long %>% 
  mutate(n_county = jitter(n_county)) %>% 
  mutate(model = case_when(
    model == "radon_avg_county_ml" ~ "ML",
    model == "radon_avg_county_nopool" ~ "No pooling"
  ))

radon3 <- radon2_long %>% 
  group_by(model) %>% 
  summarise(estimate = mean(estimate))
```


```{r echo = FALSE,out.width="80%", fig.asp = .5}
theme_set(
  theme.fom  
)
p_radon <- radon2_long %>% 
  ggplot(aes(x = n_county, y = estimate, )) +
  facet_wrap(~ model,) +
  geom_hline(aes(yintercept = estimate), data = radon3) +
  geom_errorbar(aes(ymin = estimate - SE, ymax = estimate + SE),
                color = "grey40") +
  geom_point() +
  scale_x_log10()  +
  labs(y = TeX("Intercepts, $\\alpha_j$"),
       x = "Sample size") 
p_radon  
```



*Complete pooling* is ignorant to all differences between the groups. *No pooling* is ignorant to the size of a group and to the population distribution, thereby yielding more extreme estimations. *Partial pooling* (multi level modelling; ML) shrinkgs coefficients towards the grand mean.



### Overview on the model parameters



```{r}
tidy(radon_ml1)
```


- Estimate for the average Radon level across all counties: $\hat{\mu}_a = 1.35$

- Variation of Radon levels on the house level (residual variation):  $\hat{\sigma}_y = 0.77$

- Variation of Radon levels on county level: $\hat{\sigma}_{\alpha} = 0.29$




### Adding predictors

Predictors at house level (level 1):


```{r}
radon_ml2 <- lme4::lmer(log_radon ~  floor + (1|county), data = radon)
```

Predictors at county level (level 2):

Predictors at level 2 are specified just like predictors on level 1. Let's add some fake predictor (eg., mean altitude of the county):


```{r}
radon2 <- radon %>% 
  mutate(altitude = rnorm(n = 919, mean = 300, sd = 50) )
```


```{r}
radon_ml3 <- lme4::lmer(log_radon ~  altitude + (1|county), 
                        data = radon2)
```


### Comparing models

A $\chi^2$ Test can be used to check whether the sum of the squared residuals decreases in the more complex model(s):


```{r}
anova(radon_ml1, radon_ml2)
```

The fit of model `radon_ml2` is better than that of model `radon_ml1`, according to this test.




## Case study for crossed effects



### Tutorial by DeBruine and Barr^[Preprint DOI: 10.31234/osf.io/xp5cy; CC-By 4.0]


```{r echo = FALSE, out.width="70%",}
knitr::include_graphics(file.path(pathToImages,"crossed-effects-design-crop.png"))
```


- Variable *condition* varies
  - *within*  subjects 
  - *between* items (items 1-25 vs items 26-50)

- All materials are open access:
https://osf.io/3cz2e/
  - Tutorial ([PDF](https://github.com/debruine/lmem_sim/blob/master/01.AMPSS_LMEM.pdf) oder [HTML](https://debruine.github.io/lmem_sim/index.html))
  - [R Syntax](https://raw.githubusercontent.com/debruine/lmem_sim/master/appendix1_example_code.Rmd)
  - [Github Repo](https://github.com/debruine/lmem_sim)
  - [App](http://shiny.psy.gla.ac.uk/crossed/)
  

