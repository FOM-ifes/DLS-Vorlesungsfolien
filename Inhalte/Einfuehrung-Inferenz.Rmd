```{r setup-Einfuehrung-Inferenz, echo=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Karsten Luebke
#%
# ---------------------------------------------------------------------------
source("../prelude.R")
initPart(
    "Einfuehrung-Inferenz",  # Dateiname ohne Suffix
    "EinfuehrungInferenz"      # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages = getPathToImages()
# ---------------------------------------------------------------------------

library(mosaic)

tips <- assertData("tips.csv", "https://goo.gl/whKjnl")
```
# `r nextChapter()` Einführung in die Inferenzstatistik


## Einführendes Beispiel


### Einführung: Ist die Münze gezinkt?

Jemand lädt Sie zu einem Glücksspiel ein: Die Person wirft eine Münze 10 Mal. Bei *Kopf* gewinnt die Person, bei *Zahl* gewinnen Sie. Die Person gewinnt 8 der 10 Würfe. Unterstützen die Daten den Schluss, dass die Münze gezinkt ist?

Spielen Sie im Hörsaal den Versuch mit einer *fairen* Münze nach!

Zählen Sie dann aus, ob das Ereignis "(min.) 8 von 10 Kopf" selten ist oder häufig. 

Falls das Ereignis selten ist, so sprechen die Daten *gegen* die *Unschuldsvermutung*, dass die Münze im Glücksspiel fair war.


### Die Verteilung der Stichproben aus dem Münz-Versuch

So könnte die Verteilung Ihrer Ergebnisse aussehen (hier mit $n=100$):


```{r muenz-simu, echo = FALSE, out.width = "50%"}
set.seed(1896) # Reproduzierbarkeit
muenzverteilung <- do(100) * rflip(n = 10)
#prop(~heads >= 8, data = muenzverteilung)
bargraph(~heads, data = muenzverteilung, main = "9 der 100 Stichproben hatten 8 oder mehr Kopf")
```


Das ist die Verteilung der Statistik (hier: Anteil $p$) wie sie sich gemäß einer Hypothese (hier: "Die Münze ist fair" $\pi=0.5$) ergibt.


### Übung `r nextExercise()`: Was ist ein häufiges Ereignis im Münzversuch? {.exercise type=A-B-C-D answer=B}

```{r, echo=FALSE, fig.align="right", out.width="20%"}
bargraph(~heads, data = muenzverteilung)
```

Welche der Aussagen stimmt?

A.  Wirft man 10 faire Münzen, so sind 0 bis 2 Treffer ein häufiges Ereignis.
B.   Wirft man 10 faire Münzen, so sind 4 bis 6 Treffer ein häufiges Ereignis.
C.   Wirft man 10 faire Münzen, so sind 8 bis 10 Treffer ein häufiges Ereignis.
D.   Wirft man 10 faire Münzen, so ist jede Anzahl an Treffern gleich häufig.


::: {.notes}
Antwort ***B*** ist korrekt. Wenn die Wahrscheinlichkeit "Kopf" bei einer Münze $\pi=1/2$ ist, so sollte bei sehr vielen Würfen die Anzahl der Treffer auch bei etwa $1/2$. Wirft man die Münze nicht so häufig, kann die Anzahl der Treffer auch mal deutlich von $p=1/2$ abweichen.
:::



### Was ist eine Simulation?

Man kann das Münzwerfen (allgemein: das Durchführen von Zufallsexperimenten) an den Computer delegieren; man spricht dann von einer *Simulation*:

```
Hey R,
Wiederhole das Folgende 100 Mal:
  - Wirf eine faire Münze 10 Mal,
  - zähle jedes Mal die Anzahl der Treffer (Kopf).
Ach ja, speichere das Ergebnis in einem neuen Dataframe.
Jetzt mal los.
```



## Modellierung und Simulation


### Grundgedanken der Statistik

- Innerhalb der Statistik wird versucht, aus Daten Einsichten zu gewinnen.
- Dabei wird berücksichtigt,
    - dass Variation allgegenwärtig ist,
    - dass es neben dem Signal Rauschen gibt, 
    - dass Schlüsse unsicher sind.

### Deskriptive Statistik vs. Inferenzstatistik    
    
- Die *deskriptive Statistik* fasst Daten einer Stichprobe zusammen.
- Die *Inferenzstatistik* schließt von einer Stichprobe auf eine Grundgesamtheit.

\vspace{1cm}

```{r fig-desk-vs.inf, out.width="70%", echo = FALSE}
knitr::include_graphics(file.path(pathToImages,"desk_vs_inf-crop.png"))
```



### Inferenz

Idee: Schluss von einer (zufälligen/ randomisierten) Stichprobe auf eine Population:

- Hypothesentest 
- Punktschätzung
- Konfidenzintervall


Ziel: Aussagen treffen, die über die Stichprobe hinausgehen -- und dabei berücksichtigen, dass Variation allgegenwärtig ist und Schlussfolgerungen unsicher.^[Vgl. Moore, D. (2007) The Basic Practice of Statistics, 4th edn. New York: Freeman, S. xxviii.]

## Grundlagen des Hypothesentestens


### Das Testen von Hypothesen

- Beispiele für Hypothesen sind:
  - "Die Münze ist fair"
  - "Alle drei Bierproben schmecken gleich"
  - "Abends gibt es genauso viele Raucher in der Kneipe wie Mittags"
  - "Frauen geben genauso viel Trinkgeld wie Männer".
- Inhaltliche Hypothesen und Modelle werden mathematisch/statistisch operationalisiert. Dabei ist die **Nullhypothese** $H_0$ i. d. R. die, dass es keinen Zusammenhang, keinen Unterschied gibt.
- Die **Alternativhypothese** ($H_A$ oder $H_1$; die Forschungshypothese) ist das logische Gegenteil der Nullhypothese. Die Rollen von $H_0$ und $H_A$ können nicht vertauscht werden. 
- Hypothesen beziehen sich auf die Population/ Grundgesamtheit, d. h. $\pi, \mu, \beta$. 
- Alternativhypothesen können **einseitig, gerichtet** ($<, >$) oder **zweiseitig, ungerichtet** ($\neq$) sein. 
- Anhand einer geeigneten **Teststatistik** $\delta$ werden die Stichprobendaten zusammengefasst. Ist die Wahrscheinlichkeit der Teststatistik unter $H_0$ (sehr) klein, wird diese verworfen, andernfalls nicht.


### Hypothesen testen in Analogie zu Gerichtsverfahren

- Die Beweislast liegt bei der Forschungsthese: Wir gehen von $H_0$ aus: der Angeklagte ist unschuldig, da ist nichts.
- Wenn die Beweise (Daten) gegen den Angeklagten ($H_0$) sprechen^[d.h., unter der Unschuldsvermutung (sehr) unwahrscheinlich sind], haben wir berechtigten Zweifel an der Unschuld ($H_0$).
- Wenn die Daten nicht ausreichen, um zu zeigen, dass der Angeklagte schuldig ist, so sagen wir nicht: er ist unschuldig. **Daher nie**: wir bestätigen die Nullhypothese, sondern nur, wir können die Nullhypothese nicht verwerfen. Die Abwesenheit von Belegen belegt nicht die Abwesenheit.


### Cartoon: Man darf die $H_0$ nicht akzeptieren, höchstens beibehalten

```{r echo=FALSE, out.width = "40%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2016/Caption-Contest_11-2016.jpg", "cartoon1116.jpg", pathToImages)
```
"Dr. Frankenstein akzeptierte die Nullhypothese zum letzten Mal."^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/november/2016/results) &copy; J.B. Landers, Überschrift A. Boito]

### Schema der simulationsbasierten Inferenz


```{r echo=FALSE, out.width = "70%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages,"OneTest.png"))
```

[Abbildung: Quelle: Blogbeitrag Allen Downey]{.small}^[[http://allendowney.blogspot.de/2016/06/there-is-still-only-one-test.html](http://allendowney.blogspot.de/2016/06/there-is-still-only-one-test.html)]


### p-Wert 

- Der **p-Wert** ($p$) gibt an, wie viele Stichproben ein mindestens so extremes Ergebnis haben, wie die beobachtete Stichprobe, wenn $H_0$ gilt.^[Video Lady Tasting Tea [https://youtu.be/lgs7d5saFFc](https://youtu.be/lgs7d5saFFc)]
- Anders gesagt: Der p-Wert berechnet sich als die Wahrscheinlichkeit der Teststatistik unter $H_0$.
- Der p-Wert ist die Entscheidungsgrundlage beim Testen von Nullhypothesen.

Im Beispiel des Münzversuch:
```{r fig-pwert1, echo = FALSE, out.width = "35%"}
bargraph(~heads, data = muenzverteilung, main = "9 der 100 Stichproben hatten 8 oder mehr Treffer")
```
Der p-Wert beträgt $9/100 =0.09$.


### Nutzen und Grenzen des p-Werts

- Der p-Wert bietet eine rationale (datenbasierte) Möglichkeit zu überprüfen, ob die vorliegenden Daten durch ein zu überprüfendes Modell ($H_0$) plausibel erklärt werden können.
- Der p-Wert ist definiert als Wahrscheinlichkeit des beobachteten Wert der Teststatistik (oder noch extremerer Werte) unter der Annahme, dass die $H_0$ gilt ($p(\delta^*|H_0)$).
- **Achtung**: Der p-Wert sagt nicht aus, wie wahrscheinlich die $H_0$ bei den vorliegenden Daten (Teststatistik) ist ($p(H_0|\delta^*)$). 
- Der p-Wert sagt nicht, wie relevant ein Ergebnis ist (wie groß ein Effekt ist).
- **Keine** Entscheidung sollte rein auf Basis des p-Wertes getroffen werden.
- *Vor* der Testentscheidung **immer** eine explorative Datenanalyse durchführen.

### Signifikanz

- Das vorab festgelegte **Signifikanzniveau** $\alpha$^[üblich: $\alpha=1\%, 5\%, 10\%$] eines Tests gibt die maximal zugebilligte Irrtumswahrscheinlichkeit dafür an, $H_0$ zu verwerfen, obwohl $H_0$ gilt.
- Gilt p-Wert $< \alpha$, so wird $H_0$ verworfen (zugunsten der Alternative $H_A$), ansonsten nicht.^[Song [https://www.causeweb.org](https://www.causeweb.org): [McLellan M &copy; P-Value is Low](https://www.causeweb.org/cause/resources/library/r12618)]  
- Verwirft man die $H_0$, so nennt man das Ergebnis (statistisch) *signifikant*.

### Cartoon: Signifikanzniveau

```{r echo=FALSE, out.width = "40%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2017/Caption-Contest_02-2017.jpg", "cartoon0217.jpg", pathToImages)
```

"Paläontologen haben schließlich doch den Ursprung des 5\% Signifikanzniveaus herausgefunden."^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/february/2017/results) &copy; J.B. Landers, Überschrift M. Dunlap]


### Fehlerarten

|   | Testentscheidung $H_0$  | Testentscheidung $H_A$  |
|:---|:---:|:---:|
| Realität $H_0$  | Ok | **Fehler 1. Art**^[Auch $\alpha$-Fehler genannt.  Die Wahrscheinlichkeit dieses Fehlers wird durch das Signifikanzniveau nach oben beschränkt.] |
| Realität $H_A$  | **Fehler 2. Art**^[Auch $\beta$-Fehler genannt.  Die Wahrscheinlichkeit dieses Fehlers ist schwieriger zu bestimmen, aber siehe z.B. Paket [pwr](https://cran.r-project.org/package=pwr). Bei guten Tests sinkt sie mit größerem Stichprobenumfang $n$.]  | Ok  |

Song [https://www.causeweb.org](https://www.causeweb.org): [Larry Lesser und Dominic Sousa &copy; Hypothesis on Trial](https://www.causeweb.org/cause/resources/fun/songs/hypothesis-trial)


## Testen eines Anteils

### Dreieckstest

- Drei gleichaussehende Proben, zwei sind gleich, eine **zufällige** ist anders.
- Der/ die Kandidat*in muss herausfinden, welche Probe anders ist.^[vgl. ISO 4120 [https://www.iso.org/standard/33495.html](https://www.iso.org/standard/33495.html). Vgl. auch Single-Choice Klausur: 3 Antwortalternativen, 1 richtig.]

```{r, echo=FALSE, fig.align="center", out.width="30%"}
plot(c(1,2,3), y=c(1,2,1), 
     col=c("green", "green", "red"), 
     pch=19, cex=4, ann=FALSE, axes=FALSE)
```


### Übung  `r nextExercise()`: Dreieckstest {.exercise type=A-B-C-D-E answer=B}

Wie groß ist die Wahrscheinlichkeit $\pi$, zufällig, d. h., ohne einen Unterschied zu schmecken, auf die richtige (sprich abweichende) Probe zu tippen?

A.  $\pi=0$
B.  $\pi=\rfrac{1}{3}$
C.  $\pi=\rfrac{1}{2}$
D.  $\pi=\rfrac{2}{3}$
E.  $\pi=1$

::: {.notes}
Antwort ***B*** ist korrekt, da es 3 Proben gibt, 1 davon anders ist und man durch Raten mit einer Wahrscheinlichkeit von $\frac{1}{3}$ zufällig richtig liegt.

Angenommen Sie führen mit Freunden einen solchen Dreieckstest durch.

Was würden Sie sagen wenn dort:

- $p \approx \frac{1}{3}$ richtig tippen? "Wenn es einen Unterschied gibt haben wir ihn nicht geschmeckt."
- $p \approx \frac{2}{3}$ richtig tippen? "Vielleicht haben ein paar einen Unterschied geschmeckt, vielleicht auch nicht."
- $p \approx \frac{3}{3}$ richtig tippen? "Wenn es keinen Unterschied gibt haben wir aber viel Glück gehabt."

Die genauen Einschätzungen hängen natürlich auch von der Anzahl $n$ Ihrer Freunde ab.  Bei $n=300$ wären Sie sicherer als bei $n=3$...
:::


### Kneipe statt Hörsaal

Im Rahmen einer Sonderveranstaltung der FOM Dortmund (6.10.2016)^[[https://www.fom.de/2016/oktober/kneipe-statt-hoersaal-chef-mit-humor-lohnt-sich.html](https://www.fom.de/2016/oktober/kneipe-statt-hoersaal-chef-mit-humor-lohnt-sich.html)] und Münster (9.11.2017) tippten von $n=34$ Teilnehmer\*innen $x=12$ im Rahmen eines Dreieckstest auf die richtige Probe. d. h. das *andere* Bier: Krombacher bzw. Perlenbacher.

```{r echo=FALSE, out.width = "45%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages,"Lidl-WR20160919.png"))
```
[Abbildung: Quelle: Anzeige Westfälische Rundschau, 19.9.2016]{.small}


### Simulation von Raten im Bierversuch

- Modell: Es gibt keinen Geschmacksunterschied. Dann muss geraten werden.
- Der Trefferanteil wird dann bei ca. $1/3$ liegen.
- Simulation: Wie ist die Verteilung der Treffer, wenn geraten wird?

```{r eval = FALSE}
# Paket laden, ggf. vorher einmalig installieren
library(mosaic)

# 34-facher Münzwurf mit Erfolgsw.keit 1/3
rflip(n = 34, prob = 1/3)
```


```{r echo = FALSE}
set.seed(1896)
rflip(n = 34, prob = 1/3)
```


### Simulation wenn geraten wird 

```
Wiederhole 10000 Mal:
  - Wirf 34 Mal eine dreiseitige Münze,
  - zähle die Anzahl der Treffer.
Speichere das Ergebnis.
```

```{r simu-Nullvtlg, echo = FALSE, fig.align="center", out.width="40%"}
set.seed(1896)  # Reproduzierbarkeit
Nullvtlg <- do(10000) * rflip(n = 34, prob = 1/3)
bargraph( ~ heads, data = Nullvtlg, main = "4710 der 10000 Versuche hatten 12 oder mehr Treffer")
```


```{r, include = FALSE}
Nullvtlg <- do(10000) * rflip(n = 34, prob = 1/3)
bargraph( ~ heads, data = Nullvtlg)
```

Beachte: der Anteil der Treffer variiert bei den simulierten Stichproben.

### Übung `r nextExercise()`: Simulation I {.exercise type=A-B-C-D answer=B}

```{r, echo=FALSE, fig.align="right", out.width="20%"}
bargraph( ~ heads, data = Nullvtlg)
```

Welche der Aussagen stimmt?

A.  Wenn geraten wird ist $x=12$ ein unüblicher, d. h. unwahrscheinlicher, Wert.
B.  Wenn geraten wird ist $x=12$ ein üblicher, d. h. wahrscheinlicher, Wert.
C.  Wenn geraten wird ist $x=10$ ein unüblicher, d. h. unwahrscheinlicher, Wert.
D.  Wenn geraten wird ist $x=20$ ein üblicher, d. h. wahrscheinlicher, Wert.

::: {.notes}
Antwort ***B*** ist korrekt. Wenn wir von $\pi=\frac{1}{3}$ ausgehen ("Raten"), dann kommt es recht oft vor, dass bei $n=34$ Versuchen $x=12$ richtig liegen. (Anteil in den Simulationsstudien hier: `r round(prop(~heads, success = 12, data=Nullvtlg),2)`). 10 und 12 Richtige kommen also relativ häufig vor, 20 relativ selten. 
:::


### Übung  `r nextExercise()`: Simulation II {.exercise type=A-B-C-D answer=D}

```{r, echo=FALSE, fig.align="right", out.width="20%"}
bargraph( ~ heads, data = Nullvtlg)
```

Bei welchem Wert für $x$ würden Sie bei $n=34$ vermuten, dass ein Geschmacksunterschied vorliegt, d.h., dass $\pi>\frac{1}{3}$ ist?

A.  Bei $x=5$.
B.  Bei $x=10$.
C.  Bei $x=15$.
D.  Bei $x=20$.

::: {.notes}
Auf keinen Fall bei *A*, kleine Werte liefern keine Belege für die Vermutung, dass $\pi>\frac{1}{3}$ ist und *B*, das passiert unter $\pi=\frac{1}{3}$ häufig. Evtl. bei *C*, aber ziemlich sicher bei ***D***.

Wenn $x=20$ das Ergebnis Ihrer Stichprobe wäre, würden dieses nicht gut zum Modell "Raten" ($\pi=\frac{1}{3}, n=34$) passen.
:::


## Den Unterschied zwischen zwei Gruppen testen


### Beispiel: Geschlecht und Klausurpunkte

- Inhaltliche Forschungsthese: Es gibt einen Unterschied im Lernergebnis Statistik zwischen Männern und Frauen (ungerichtet^[Eine ungerichtete Hypothese ist der Standardfall.]).
- Mathematische Operationalisierung: z.B. $\mu$: Mittelwert der Klausurpunktzahl in der Population.
$$H_0: \mu_{\text{Mann}} =  \mu_{\text{Frau}} \quad vs. \quad  H_A: \mu_{\text{Mann}} \neq \mu_{\text{Frau}}$$
- Teststatistik: Mittelwert der Klausurpunktzahl in der Stichprobe: $\bar{x}_{\text{Mann}}, \bar{x}_{\text{Frau}}$.
- Sollte $\bar{x}_{\text{Mann}} \gg \bar{x}_{\text{Frau}}$ oder $\bar{x}_{\text{Mann}} \ll \bar{x}_{\text{Frau}}$ sein, ist dies, wenn die Nullhypothese gilt, unwahrscheinlich.^[Abhängig vom Stichprobenumfang und Streuung.]
- Allgemeiner: Es soll getestet werden, ob sich der Mittelwert eines Merkmals zwischen zwei Gruppen (in der Populationen) unterscheidet.

### Beispiel: Quizze und Klausurerfolg

- Inhaltliche Forschungsthese: Studierende, die an den Quizzen teilnehmen, bestehen häufiger die Klausur (gerichtet^[Eine gerichtete Hypothese muss aber inhaltlich (z. B. Literatur) begründet sein!]).
- Mathematische Operationalisierung: z.B. $\pi$: Anteil derjenigen, die die Klausur bestehen, in der Population:
$$H_0: \pi_{\text{Quiz}} \leq  \pi_{\text{kein Quiz}} \quad vs. \quad  H_A: \pi_{\text{Quiz}} > \pi_{\text{kein Quiz}}$$
- Teststatistik: Anteil derjenigen, die die Klausur bestehen, in der Stichprobe: $p_{\text{Quiz}}, p_{\text{kein Quiz}}$.
- Sollte $p_{\text{Quiz}} \gg p_{\text{kein Quiz}}$ sein, ist dies, wenn die Nullhypothese gilt, unwahrscheinlich.^[Abhängig vom Stichprobenumfang.] 
- Allgemeiner: Es soll getestet werden, ob sich der Anteil eines Merkmals zwischen zwei Gruppen (in der Population) unterscheidet.



### Permutieren löst den Zusammenhang zweier Variablen {.shrink}

Beispiel:

<div class="columns"><div class="column" width="50%">
**Original:**

|Name | Geschlecht | Größe|
|-----|------------|------|
Ahmet| m| 180
Gabi| w| 170
Max| m| 186
Susi| w| 172

$$\bar{x}_m-\bar{x}_f=\frac{180+186}{2}-\frac{170+172}{2}=12$$
</div><div class="column" width="50%">

**Nach der Permutation von Geschlecht:**

|Name | Geschlecht | Größe|
|-----|------------|------|
Ahmet| m| 180
Gabi| m| 170
Max| w| 186
Susi| w| 172

$$\bar{x}_m-\bar{x}_f=\frac{180+170}{2}-\frac{186+172}{2}=-4$$

</div></div>

- Das Permutieren löst den Zusammenhang von *Geschlecht* und *Größe*. 
- Die $H_0$ nimmt an, dass die Verteilung (der Größe) in beiden Gruppen (des Geschlechts) gleich ist: das Geschlecht kann *getauscht* werden ohne dass sich die Verteilung ändert.
- Durch die Permutation wird also eine Stichprobe im Sinne der $H_0$ erzeugt.



### Ablauf des Permutationstest

Vorraussetzung: Zufällige Stichprobe (Permutation) oder zufällige Zuordnung (Randomisation).


- Wiederhole oft (z.B.  $10000 \times$):
    - Mische die $n_A+n_B$ Beobachtungen.
    - Ordne zufällig $n_A$ Beobachtungen der ersten Stichprobe zu, die restlichen der zweiten.
    - Berechne die Differenz der zwei Anteile. Analoges gilt für andere Teststatistiken, z.B. Mittelwertsdifferenzen.
- Zeichne ein Histogramm für die Differenz der 10000 Anteile.
- Zähle wie oft der beobachtete Wert der Testatatistik in der simulierten Verteilung vorkommt.
- Der p-Wert ist der Anteil der zufälligen Teststatistiken, die mindestens so groß sind wie der beobachtete Wert.^[Bei ungerichteten, zweiseitigen Tests im Absolutbetrag.] 


### Analyse des Trinkgeld-Datensatzes

Einlesen der Datensatzes *tips*^[Bryant, P. G. and Smith, M (1995) Practical Data Analysis: Case Studies in Business Statistics. Homewood, IL: Richard D. Irwin Publishing]:

```{r, eval= FALSE, message=FALSE}
download.file("https://goo.gl/whKjnl", destfile = "tips.csv")
tips <- read.csv2("tips.csv")

# Alternativ - heruntergeladene Datei einlesen:
# tips <- read.csv2(file.choose()) 
```


### Verteilung der Differenz beim Permutationstest

Histogramm der Differenz des Raucheranteil zwischen Lunch und Dinner auf Basis von 10000 simulierten Daten *ohne* Unterschied im Raucheranteil der Tageszeit -- Modell $H_0$:

```{r Nullvtlg_k, echo = FALSE}
set.seed(1896) # Reproduzierbarkeit
Nullvtlg_k <- do(10000) * diffprop(smoker ~ shuffle(time), 
                                   success = "Yes", data=tips)
```


```{r, echo=FALSE, fig.align="center", out.width="50%"}
library(gridExtra)
p1 <- histogram( ~ diffprop, data = Nullvtlg_k, main="Simulation H_0: Differenz Anteil",
                 v=diffprop(smoker ~ time, success = "Yes", data=tips), nint = 12)

p1
```

Der p-Wert lässt sich berechnen, indem man die Zahl der simulierten Daten auszählt, deren (absoluter) Wert mindestens so hoch ist wie in der beobachteten, echten, Stichprobe.


### So mischt man mit R: `shuffle()`

```{r, message=FALSE}
# Stichprobe: Beobachtungen 1 bis 10
obs <- 1:10 
obs

# Zufallszahlengenerator setzen: Reproduzierbarkeit
set.seed(1896)

# Permutation:
shuffle(obs) 
```


### Permutation der unabhängigen Variable

Beispiel: Unterscheidet sich  (in der Population) der Raucheranteils mittags vom Raucheranteil abends?

- $H_0$: Kein Unterschied/ Zusammenhang in der **Population**:
- Unterschied Raucheranteil in der Population $\pi_{Lunch}-\pi_{Dinner}=0$, beobachteter Unterschied in der Stichprobe $p_{Lunch}-p_{Dinner}=`r round(diffprop(smoker ~ time, success = "Yes", data=tips),2)`$ innerhalb der normalen Variation $\neq 0$.
- $H_A$: Der Raucheranteil ist *unterschiedlich* in den zwei Gruppen (d.h. mittags vs. abends).

```
Wiederhole 10000 Mal:
  - Berechne die Differenz des Raucheranteils (Mittags vs. Abends)
  -  dabei soll die Variable "time" jedes Mal gemischt werden.
Speichere das Ergebnis.
```

### Übung  `r nextExercise()`: Testentscheidung {.exercise type=A-B-C answer=B}

```{r, echo=FALSE, fig.align="right", out.width="20%"}
histogram( ~ diffprop, data = Nullvtlg_k, main="Simulation H_0: Differenz Anteil",
                 v=diffprop(smoker ~ time, success = "Yes", data=tips), nint = 12)
```

Wie wahrscheinlich ist der in der Stichprobe beobachtete Anteilsunterschied?

A.  Der in der Stichprobe beobachtete Anteilsunterschied an Rauchern ist sehr selten in der simulierten Verteilung nach $H_0$.
B.  Der in der Stichprobe beobachtete Anteilsunterschied an Rauchern ist nicht selten in der simulierten Verteilung nach $H_0$.
C.  Der in der Stichprobe beobachtete Anteilsunterschied an Rauchern kommt in den simulierten Stichproben nicht vor.

::: {.notes}
Der in der Stichprobe beobachtete Unterschied beim Anteil der Raucher ist, wenn die Nullhypothese gilt, nicht unüblich, also eher häufigt. Daher ist **B** richtig.
:::


### Cartoon: Signifikanz

```{r echo=FALSE, out.width = "50%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2018/Caption-Contest_04-2018.jpg", "cartoon0418.jpg", pathToImages)
```
"Beachte, dass die signifikanten Ereignisse an den Rändern auftauchen."^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/april/2018/results) &copy; J.B. Landers, Überschrift D. Nandy]
 

### p-Wert zum Zusammenhang von Rauchen und Tageszeit


```{r, include=FALSE, p-wert-smoker-time}
diff_smoker_time <- diffprop(smoker ~ time, data = tips)
diff_smoker_time
p.smoker_time <- prop(~abs(diffprop) >= abs(diff_smoker_time), data = Nullvtlg_k)
p.smoker_time
```

```{r, echo=FALSE, fig.align="center", out.width="50%"}
library(gridExtra)
p1 <- histogram( ~ diffprop, data = Nullvtlg_k, main="Simulation H_0: Differenz Anteil",
                 v=diffprop(smoker ~ time, success = "Yes", data=tips), nint = 12)

p1
```

Falls die $H_0$ richtig ist ($\pi_{Lunch}-\pi_{Dinner}=0$), dann liegt die Wahrscheinlichkeit einen (absoluten) Anteilsunterschied (($|p_{Lunch}-p_{Dinner}|$)) von mindestens `r abs(round(diff_smoker_time, 2))`  zu beobachten bei `r round(p.smoker_time, 2)`.

### Übung  `r nextExercise()`: Fehlerart {.exercise type=A-B-C answer=B}

Mit einem p-Wert von `r round(p.smoker_time, 2)` kann die Nullhypothese $\pi_{Lunch}-\pi_{Dinner}=0$ zum Signifikanzniveau $\alpha=0.05$ nicht verworfen werden. Angenommen, in Wirklichkeit liegt ein Unterschied im Anteil der Population vor. Welcher Fehler wurde begangen?

A.  Fehler 1. Art.
B.  Fehler 2. Art.
C.  Kein Fehler.

::: {.notes}
***B***: Ein Fehler 2. Art liegt vor, wenn in Wirklichkeit $H_A$ gilt, die Testentscheidung aber lautet, dass $H_0$ nicht verworfen wird.
:::


## Zwei-Gruppen Test mit R

### A/B Test

Unter $H_0$: Kein Unterschied in der Verteilung zweier Stichproben (Gruppen) in der **Population**:

- Kategorial: Unterschied Raucheranteil in der Population $\pi_{Lunch}-\pi_{Dinner}=0$, beobachteter Unterschied in der Stichprobe $p_{Lunch}-p_{Dinner}=`r round(diffprop(smoker ~ time, success = "Yes", data=tips),2)`$ innerhalb der normalen Variation $\neq 0$.

- Numerisch: Unterschied Mittelwerte Rechnungshöhe in der Population $\mu_{Lunch}-\mu_{Dinner}=0$, beobachteter Unterschied in der Stichprobe $\bar{x}_{Lunch}-\bar{x}_{Dinner}=`r round(diffmean( total_bill ~ time, data=tips),2)`$ innerhalb der normalen Variation $\neq 0$.

### Permutationstest 

```{r}
set.seed(1896) # Reproduzierbarkeit
Nullvtlg_k <- do(10000) * diffprop(smoker ~ shuffle(time), 
                                   success = "Yes", data=tips)
Nullvtlg_n <- do(10000) * diffmean(total_bill ~ shuffle(time), 
                                   data=tips)
```

```{r, echo=FALSE, , fig.align="center", out.width="60%"}
library(gridExtra)
p1 <- histogram( ~ diffprop, data = Nullvtlg_k, main="Simulation H_0: Differenz Anteil",
                 v=diffprop(smoker ~ time, success = "Yes", data=tips), nint = 12)
p2 <- histogram( ~ diffmean, data = Nullvtlg_n, main="Simulation H_0: Differenz Mittelwert",
                 v=diffmean(total_bill~ time, data=tips), nint = 12)
grid.arrange(p1,p2, ncol=2)
```

### Übung  `r nextExercise()`: Testentscheidung {.exercise type=A-B-C answer=B}

Unter welcher Nullhypothese ist der in der Stichprobe beobachtete Unterschied unwahrscheinlicher?

A.  Verteilung Anteil Raucher in beiden Gruppen gleich ($\pi_{Lunch}-\pi_{Dinner}=0$).
B.  Verteilung Rechnungshöhe in beiden Gruppen gleich ($\mu_{Lunch}-\mu_{Dinner}=0$).
C.  Bei beiden ungefähr gleich.

::: {.notes}
Der in der Stichprobe beobachtete Unterschied beim Anteil der Raucher ist, wenn die Nullhypothese gilt, nicht so unüblich wie der Unterschied bei der Rechnungshöhe, also ist ***B*** korrekt.
:::

## Parameter schätzen


### Grundbegriffe der Parameterschätzung

- Bei einer **Punktschätzung** wird z.B. ein unbekannter Parameter/ Wert der *Population* anhand eines Wertes der *Stichprobe* geschätzt, z.B. $\hat{\mu}=\bar{x}$, $\hat{\sigma}={sd}$, $\hat{\pi}=p$. Das "Dach" ^ ist das Symbol für die Schätzung (engl.: (point) estimate).
- Der **Standardfehler** (engl.: standard error, $se$) beschreibt die Streuung (Standardabweichung) eines Schätzwertes, z.B. für den arithmetischen Mittelwert $\bar{x}$: $se=\frac{sd}{\sqrt{n}}$, d.h. $se$ sinkt mit steigendem $n$.
- Die **Anzahl Freiheitsgrade** (engl.: degrees of freedom, $df$) gibt an, wie viele Beobachtungen dabei *frei* sind: Ist der Mittelwert von $n$ Beobachtungen bekannt, so ist $df=n-1$.


### Punktschätzung des Raucheranteils 

In der Stichprobe liegt der Raucheranteil der Rechungszahler*innen bei $p=`r round(prop(~smoker, data = tips, success = "Yes"), 2)`$:

```{r}
prop(~smoker, data = tips, success = "Yes")
```

Der Punktschätzer für den Raucheranteil in der Population ist daher:

$$\hat{\pi}=p=`r round(prop(~smoker, data = tips, success = "Yes"), 2)`$$


### Übung  `r nextExercise()`: Ergebnis Punktschätzung {.exercise type=yesno answer=no}

Wird mit Sicherheit in der Population gelten $\pi=\hat{\pi}=p=`r round(prop(~smoker, data = tips, success = "Yes"), 2)`$?

- Ja.
- Nein.

::: {.notes}
Eine andere Stichprobe würde evtl. ein anderes Ergebnis liefern, was die Population ergibt, wissen wir nicht, also ***Nein***.
:::


### Konfidenzintervall

- Ein **Konfidenzintervall** gibt einem Bereich an, der den wahren, unbekannten Wert der Population mit einer gegebenen Sicherheit (z. B. $95\,\%=1-\alpha=100\,\%-5\,\%$) überdeckt, d. h., den Anteil der so konstruierten Konfidenzintervalle, die den Wert enthalten.^[Song [https://www.causeweb.org](https://www.causeweb.org): [Larry Lesser &copy; Call It Maybe](https://www.causeweb.org/cause/resources/fun/songs/call-it-maybe)]
- Je größer die Sicherheit (z. B. $99\,\%$ statt $95\,\%$), desto breiter ist das Intervall.^[Häufig bei $n>30$: $95\,\%$-KI $\approx \delta^* \pm (2 \cdot se)$]
- Je größer der Stichprobenumfang, desto kleiner das Konfidenzintervall (unter sonst gleichen Umständen): der Standardfehler $se$ fällt mit $n$.

### Überdeckung durch Konfidenzintervall

```{r, echo=FALSE, , fig.align="center", out.width="80%"}
set.seed(1896) # Reproduzierbarkeit
CIsim(n=10, samples=100)    
```


### Ziehen mit Zurücklegen {.shrink}

<div class="columns"><div class="column" width="50%">

**Original:**

|Name | Geschlecht | Größe|
|-----|------------|------|
Ahmet| m| 180
Gabi| w| 170
Max| m| 186
Susi| w| 172

$$\bar{x}_m-\bar{x}_f=\frac{180+186}{2}-\frac{170+172}{2}=12$$

</div><div class="column" width="50%">
**Bootstrap-Stichprobe:**

|Name | Geschlecht | Größe|
|-----|------------|------|
Ahmet| m| 180
Ahmet| m| 180
Max| m| 186
Susi| w| 172


$$\bar{x}_m-\bar{x}_f=\frac{180+180+186}{3}-\frac{172}{1}=10$$
</div></div>

Ziehe aus der Originalstichprobe mit Zurücklegen eine neue vom gleichen Umfang und berechne Statistik. Wiederhole dies oft und schätze damit die Verteilung der Statistik der Stichprobe.

### Schema Bootstrap


```{r echo=FALSE, out.width = "70%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages,"bootstrap.png"))
```

\small{Abbildung: Quelle: Lock, Robin, Patti Frazer Lock, Kari Lock Morgan, Eric F. Lock, and Dennis F. Lock (2012): Statistics: UnLOCKing the Power of Data. Wiley.}

### Ziehen mit Zurücklegen in R: `resample()`

Simuliere zufällige Stichprobenziehung: **Ziehe mit Zurücklegen** aus der gegebenen Stichprobe eine neue vom gleichen Umfang:

```{r}
# Stichprobe: Beobachtungen 1 bis 10
obs <- 1:10 
obs

# Zufallszahlengenerator setzen: Reproduzierbarkeit
set.seed(1896)

# Resampling:
resample(obs) 
```

### Ablauf: Bootstrap

Vorraussetzungen: 

- Zufällige Stichprobe oder zufällige Zuordnung. 
- Nicht zu kleine Stichprobe.^[$n\geq 35$]

Beispiel: Bootstrap-Perzentil-Intervall^[Es gibt weitere, teilweise exaktere Bootstrap-Methoden.] für eine Stichprobe:

- Wiederhole z.B.  $10000 \times$
    - Ziehe mit Zurücklegen eine Stichprobe vom Umfang $n$ aus der Originalstichprobe.
    - Berechne Statistik, z.B. Antei $p$ der Bootstrap-Stichprobe. Analog für andere Statistiken, z.B. Mittelwert.
- Zeichne Histogramm der Bootstrap-Verteilung der Statistik.
- Das $95\,\%$-Bootstrap-Perzentil-Intervall sind die mittleren $95\,\%$ der Bootstrap-Verteilung.

### Bootstrap-Konfidenzintervall Raucheranteil

```
Wiederhole 10000 Mal:
  - Berechne den Anteil der Raucher,
  - Der Datensatz "tips" soll dabei jedes Mal resampelt werden.
Speichere das Ergebnis.
```


```{r, fig.align="center", out.width="40%", echo = FALSE}
set.seed(1896) # Reproduzierbarkeit
Bootvtlg_smoker <- do(10000) * prop(~smoker, 
                             data = resample(tips), success = "Yes")
histogram(~prop_Yes, data = Bootvtlg_smoker,
          v = c(quantile(~ prop_Yes, data = Bootvtlg_smoker, probs=c(0.025, 0.975))[1],
                quantile(~ prop_Yes, data = Bootvtlg_smoker, probs=c(0.025, 0.975))[2]))
```


Das Konfidenzintervall erstreckt sich über alle nicht-seltenen simulierten Stichproben; nur die extremsten $2.5\%$ der Stichproben links und rechts lassen wir außen vor (vertikalen Linien), um ein $95\%$-Konfidenzintervall zu erhalten.

### Übung  `r nextExercise()`: Konfidenzintervall {.exercise type=A-B-C answer=A}

```{r, echo=FALSE, fig.align="right", out.width="20%"}
histogram(~prop_Yes, data = Bootvtlg_smoker,
          v = c(quantile(~ prop_Yes, data = Bootvtlg_smoker, probs=c(0.025, 0.975))[1],
                quantile(~ prop_Yes, data = Bootvtlg_smoker, probs=c(0.025, 0.975))[2]))
```

Auf Basis der Trinkgeld-Daten und der Bootstrap-Simulation auf der letzten Seite. Welche Aussage stimmt?

A.  Der Mittelwert des Raucheranteils der Bootstrap-Verteilung gleicht/ähnelt dem Raucheranteil in der echten Stichprobe.
B.  Ein Raucheranteil von $0.40$ ist ein ungewöhnlicher Wert.
C.  Mehr Bootstrap-Stichproben (d.h., z.B. `do(1000000)`) verkleinert das Konfidenzintervall.


::: {.notes}
***A*** ist die richtige Lösung. *B* ist falsch, da ein Anteil von $0.40$ bei diesen Bootstrap-Stichproben nicht ungewöhnlich ist. Ein größerer Stichprobenumfang $n$ würde zwar den Standardfehler $se$ verkleinern (und damit das Konfidenzintervall), aber mehr Bootstrap-Stichproben (*C*) führen nicht zu einem kleineren Konfidenzintervall.
:::

### Verzerrung und Standardfehler

Überprüfung ob das Bootstrap-Intervall ggf. verzerrt ist: $\overline{\widehat{\delta}^*}-\hat{\delta}$

```{r}
mean( ~ prop_Yes, data = Bootvtlg_smoker) - 
  prop(~smoker, data = tips, success = "Yes")
```

Bootstrap-Schätzung des Standardfehlers ($se$):

```{r}
sd( ~ prop_Yes, data = Bootvtlg_smoker)
```


## Abschluss

### Cartoon: Statistik

```{r echo=FALSE, out.width = "50%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2018/Caption-Contest_09-2018.jpg", "cartoon0918.jpg", pathToImages)
```
"Am Anfang ein bisschen schwer zu verdauen, aber sehr nahrhaft und voll mit Vitaminen $\alpha, \hat{\pi}, \bar{x}$ und besonders $\mu$ und $\sigma$."^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/september/2018/results) &copy; J.B. Landers, Überschrift G. Baugher]

### Simulationsbasierte Inferenz als ein übergreifendes Prinzip


- Simulationsbasierte Inferenz bietet *ein* Verfahren für viele Fragen der Inferenzstatistik.

**Alternative**: Test mit theoretischen Verteilungsannahmen unter $H_0$.^[Häufig approximativ oder asymptotisch. Bspw. $t-, \chi^2-, F-$ Verteilungen.]

- Solche "klassischen" Tests basieren auf jeweils unterschiedlichen Methoden und Annahmen.
- Nicht für jede Fragestellung sind die theoretischen Verteilungen bekannt.


### Schlussmöglichkeiten (Wiederholung)

+-----------------------+------------------------+------------------------------+
|                       | **zufällige** \        | **keine zufällige** \        |
|                       | **Zuordnung**          | **Zuordnung**                |    
+=======================+========================+==============================+
| **zufällige** \       | Kausalschluss, \       | kein Kausalschluss, \        |
| **Stichprobe**        | generalisierbar \      | Aussage generalisierbar \    |
|                       | für die Population     | für die Population           |
+-----------------------+------------------------+------------------------------+
| **keine zufällige** \ | Kausalschluss, \       | kein Kausalschluss, \        |                    
| **Stichprobe**        | nur für die Stichprobe | Aussage nur für die \        |
|                       |                        | Stichprobe                   |
+-----------------------+------------------------+------------------------------+


### Überblick zu den Simulationstechniken dieses Skripts


- **Einfache Simulation** zur Analyse einer Statistik: simuliere zufällige Datenentstehung im Modell ($H_0$) und vergleiche die Stichprobe mit den simulierten Daten.
- **Permutationstest** zum Test eines Unterschieds bzw. Zusammenhang zwischen zwei Gruppen bzw. zweier Merkmale: simuliere zufällige Zuordnung und vergleiche die Stichprobe mit den simulierten Daten, wenn die Verteilung gleich wäre ($H_0$).
- **Bootstrap** zur Berechnung eines Konfidenzintervalls: Simuliere zufälliges Ziehen einer Stichprobe mit Zurücklegen.

### Monte Carlo in R

- **Permutationstest**, hier: simuliere zufällige Zuordnung^[d.h. ohne Zurücklegen]. Simuliere Verteilung einer Statistik unter der Annahme, dass kein Unterschied vorliegt (Modell $H_0$), u.a. zur Bestimmung von p-Werten.

```{r, eval=FALSE}
do(oft) * statistik(y ~ shuffle(x), data = Daten)
```

- **Bootstrap**, hier: simuliere zufälliges Ziehen einer Stichprobe^[d.h. mit Zurücklegen]. Schätze Verteilung einer Statistik der Stichprobe, u.a. zur Bestimmung von Konfidenzintervallen oder Standardfehlern.

```{r, eval=FALSE}
do(oft) * statistik(y ~ x, data = resample(Daten))
```


### Übersicht Teststatistiken (Auswahl)


+---------------------+---------------------+-------------------------------------+
| **Y**               | **X**               | **Teststatistik**                   |
+=====================+=====================+=====================================+
| kategorial - binär  |                     | Anteil $p$                          | 
+---------------------+---------------------+-------------------------------------+
| kategorial          |                     | Verhältnisvergleich *beobachtet* und *erwartet*: $\chi^2$ | 
+---------------------+---------------------+-------------------------------------+
| numerisch           |                     | Mittelwert $\bar{x}$                |
+---------------------+---------------------+-------------------------------------+
| kategorial - binär  | kategorial - binär  | Differenz Anteile $p_B-p_A$         | 
+---------------------+---------------------+-------------------------------------+
| numerisch           | kategorial - binär  | Differenz Mittelwerte $\bar{x}_B-\bar{x}_A$| 
+---------------------+---------------------+-------------------------------------+
| kategorial          | kategorial          | Verhältnisvergleich *beobachtet* und *erwartet*: $\chi^2$| 
+---------------------+---------------------+-------------------------------------+
| numerisch           | kategorial          | Streuungsvergleich *zwischen Gruppen* und *innerhalb Gruppen*: $F$| 
+---------------------+---------------------+-------------------------------------+
| numerisch           | numerisch           | Korrelationskoefizient $r$ oder Steigung $\hat{\beta}$ lineare Regression | 
+---------------------+---------------------+-------------------------------------+
| kategorial          | numerisch           | Steigung $\hat{\beta}$ logistische oder multinomiale Regression | 
+---------------------+---------------------+-------------------------------------+

::: {.scriptsize}
Binär: Zwei Ausprägungen: Ja, Nein; $A, B$.
:::



### Grundlagen Inferenz

- Vorraussetzung: Unabhängig, identisch verteilte Daten, z. B. aufgrund einer zufälligen Stichprobe oder einer zufälligen Zuordnung.
- `Y~1`: (d. h. ohne unabhängige Variable): Modellierte Verteilung (z.B. Binomial- oder Normalverteilung) von $Y$ hängt von einem interessierenden Parameter ab. Nullhypothese z. B. $\pi=\pi_0$ oder $\mu=\mu_0$.
- `Y~X`: Die Modellierung der Verteilung von $Y$ hängt evt. von $X$ ab: Nullhypothese: Die Verteilung von $Y$ ist für alle $X$ gleich.
- Bei den Regressionsverfahren können mehrere unabhängige Variablen $X$ (mit unterschiedlichem Skalenniveau) in der Modellierung berücksichtigt werden.

**Verfahrensübersicht** (Mindmap): [https://coggle.it/diagram/Vxlydu1akQFeqo6-/t/inference](https://coggle.it/diagram/Vxlydu1akQFeqo6-/t/inference)

### Übersicht Inferenzverfahren R mosaic (Auswahl)

::: {.scriptsize}

+---------------------+---------------------+------------------------+-------------------+
| **Y**               | **X**               | **Simulationsbasiert** | **Parametrisch** [^note1] |
+=====================+=====================+========================+===================+
| kategorial - binär  |                     | `prop()`               | `binom.test()`    | 
+---------------------+---------------------+------------------------+-------------------+
| kategorial          |                     | `xchisq.test()`        | `xchisq.test()`   |
+---------------------+---------------------+------------------------+-------------------+
| numerisch           |                     | `mean()`               | `t.test()`        |
+---------------------+---------------------+------------------------+-------------------+
| kategorial - binär  | kategorial - binär  | `diffprop()`           | `prop.test()`     | 
+---------------------+---------------------+------------------------+-------------------+
| numerisch           | kategorial - binär  | `diffmean()`           | `t.test()`        | 
+---------------------+---------------------+------------------------+-------------------+
| kategorial          | kategorial          | `xchisq.test()`        | `xchisq.test()`   |
+---------------------+---------------------+------------------------+-------------------+
| numerisch           | kategorial          | `aov()`                | `aov()`           |
+---------------------+---------------------+------------------------+-------------------+
| numerisch           | numerisch           | `cor()`, `lm()`        | `cor.test()`, `lm()` |
+---------------------+---------------------+------------------------+-------------------+
| kategorial  - binär | numerisch           | `glm(family = binomial)` | `glm(family = binomial)` |
+---------------------+---------------------+------------------------+-------------------+

- Permutationstest: `do(oft) * statistik(y ~ shuffle(x), data = Daten)`: Kritische Werte, p-Werte.
- Bootstrap: `do(oft) * statistik(y ~ x, data = resample(Daten))`: Konfidenzintervall, Standardfehler.

:::

[^note1]: Verteilungsannahmen!



```{r finish-Einfuehrung-Inferenz, include=FALSE}
rm(pathToImages)
finalizePart(partname)
```

