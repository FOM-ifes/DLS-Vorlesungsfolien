```{r setup-PLS-PM, include=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Oliver Gansser
#%
# ---------------------------------------------------------------------------
source("../prelude.R")
initPart(
    "PLS-PM",  # Dateiname ohne Suffix
    "PLS-PM"   # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages = getPathToImages()
# ---------------------------------------------------------------------------

library(mosaic)
library(plspm)


```
# `r nextChapter()` PLS Path Modeling


### Was sind Strukturgleichungsmodelle (SEM)

Strukturgleichungsmodelle sind vor allem in der wissenschaftlichen Forschung weit verbreitet, während die praktische Anwendung dieser Modelle selten, aber nicht unbedeutend ist. 

SEM kombinieren die Methoden der Faktoranalyse und Regressionsanalyse mit der Möglichkeit, beide Modelle gleichzeitig zu schätzen^[Kline, R. B. (2016). Principles and practice of structural equation modeling. New York: Guilford]. Im SEM werden Rückschlüsse auf die Abhängigkeiten zwischen Konstrukten (latente Variablen oder Faktoren) durch Varianzen und Kovarianzen von Indikatoren (manifeste Variablen) gezogen. Der Vorteil ist, dass eine größere Anzahl von voneinander abhängigen Abhängigkeiten analysiert und gleichzeitig latente Variablen in diese Beziehungen einbezogen werden können. Schließlich geht es darum, Theorien über die Existenz latenter Variablen und deren Zusammenhänge zu untersuchen.


### Beispiel SEM

Strukturgleichungsmodell zur Nutzungsabsicht von LBS (Location based services)

```{r echo=FALSE, out.width = "50%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages,"BSP_SEM"))
```
Quelle: Gansser, O.; Krol, B. (2017): Potenziale von Location-based Services für die Marktforschung, in: Gansser, A. O.; Krol, B. (Hrsg.): Moderne Methoden der Marktforschung, Wiesbaden: Springer.


### Aufbau und Analyse eines SEM 

Strukturgleichungsmodelle werden auf der Grundlage theoretischer Überlegungen formuliert. Die Entwicklung des Modells zur Akzeptanz ortsbezogener Dienste lässt sich beispielsweise aus vier grundlegenden Theorien zur Verhaltensforschung in der Techniknutzung ableiten: 

- Theory of Reasoned Action (TRA), Theory of Planned Behavior (TPB), Technology Acceptance Model (TAM) and Theory of Acceptance und Use of Technology (UTAUT). 
- Die Beziehungen zwischen den latenten Variablen stellen letztlich die zu untersuchenden Hypothesen dar.


### Operationalisierung der latenen Variablen

Für die Operationalisierung der latenten Konstrukte muss entschieden werden, ob eine reflektive oder formative Spezifikation der Messmodelle sinnvoll ist. 

- In **reflektierenden Messmodellen** wird angenommen, dass die Werte der beobachtbaren Indikatoren durch das latente Konstrukt verursacht werden. Eine Änderung des latenten Konstrukts würde sich in einer Änderung aller ihm zugeordneten Indikatoren niederschlagen. 

- In **formativen Messmodellen** ist die Beziehung zwischen Indikatoren und latenten Konstrukten genau das Gegenteil. Hier bewirken die beobachtbaren Indikatoren die Entwicklung des latenten Konstrukts.


### Messmodelle für die latenten Variablen

```{r echo=FALSE, out.width = "70%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages,"ref_form"))
```


### Modellschätzung SEM

Die Schätzung der Parameter des Modells kann auf unterschiedliche Weise erfolgen. Grundsätzlich gibt es zwei verschiedene Ansätze. 

- Für die meisten Forscher ist SEM gleichbedeutend mit der Durchführung von **kovarianz-basiertem SEM** (CB-SEM). Das Ziel von CB-SEM ist die Theorieprüfung, die Theoriebestätigung oder der Vergleich alternativer Theorien. Die Parameterschätzung des Modells erfolgt gleichzeitig. 

- Das Ziel bei **varianzbasiertem SEM** (Partial Least Squares SEM oder PLS-SEM) ist die Vorhersage von Schlüssel-Zielkonstrukten oder die Identifizierung von Schlüsseltreiberkonstrukten. Die Faktorwerte werden zunächst sukzessive für die Messmodelle ermittelt und in einem zweiten Schritt als Messwerte für die latenten Variablen in einer Regressionsanalyse verwendet.


### Bewertung des Modells

Die Auswertung der Testergebnisse erfolgt mit verschiedenen Qualitätskriterien und folgerichtigen statistischen Tests. 

Es wird nach 

- globalen und 
- lokalen Qualitätskriterien 

unterschieden. 

Während **globale Qualitätskriterien** eine Bewertung der Konsistenz des Gesamtmodells mit den gesammelten Daten erlauben, erlauben **lokale Qualitätskriterien** die Überprüfung der Messqualität einzelner Indikatoren und latenter Variablen. Dies hängt auch von der Art der Parameterschätzung ab.^[An dieser Stelle wird auf die zahlreiche Fachliteratur zum Thema SEM verwiesen.]


### Warum PLS-PM (Partial Least Squares Path Modeling)

PLS-PM bietet folgende Vorteile^[Sanchez, G. (2013) PLS Path Modeling with R,
Trowchez Editions, Berkeley, 2013.

- Es gibt keine Verteilungsannahmen.
- Nicht auf einen Datengenerierungsprozess und kausale Modellierungsinterpretationen angewiesen.
- Behandelt die Daten "nur" als Datensatz.
- Technik zur Analyse eines Systems von Beziehungen zwischen mehreren Blöcken von Variablen.
- Technik ist als Vorhersagemethode geeignet (kann für erklärende und bestätigende Zwecke eingesetzt werden).


### Das Paket `plspm`

`plspm` ist ein R-Paket zur Durchführung von Partial Least Squares Path Modeling (PLS-PM) Analysen.

Literatur: 

- [Sanchez, G. (2013) PLS Path Modeling with R Trowchez Editions. Berkeley, 2013.](http://www.gastonsanchez.com/PLS_Path_Modeling_with_R.pdf)
- [Introduction to the R package plspm](https://cran.r-project.org/web/packages/plspm/vignettes/plspm_introduction.pdf)


Installation

```{r eval=FALSE}
# Installation des Pakets plspm
install.packages("plspm")

```


```{r echo=TRUE}
# Laden von plspm
library(plspm)
```


### Durchführung einer PLS-PM Analyse

Am Anfang eine jeglichen Forschung steht eine Forschungsfrage^[Nach einer ausgiebigen Literaturrechere in der wissenschafltichen Fachliteratur]: 

**Welchen Einfluss haben Social Media-Influencer im Vergleich zu Traditionellen Medien?** 

Die Anregung für diese Forschungsfrage ist aus folgendem Artikel^[Das Niveau dieses Artikels ist nicht besonders hoch, reicht aber für Demonstrationszwecke]:

- Abzari, A.; Ghassemi, R. A.; Vosta, L.N.  Analysing the effect of social media on brand attitude and purchase
intention: the case of Iran Khodro company, in: Procedia - Social and Behavioral Sciences 143 ( 2014 ), p. 822 – 826


### Überblick über die Konstrukte des Modells

- Traditionelle Medien (TM): Es soll die Zufriedenheit und die Präferenz traditioneller Medien gemessen werden. 
- Social Media Influencer (SM): Es soll die Zufriedenheit mit Social Media Influencern bei Instagram gemessen werden.
- Markeneinstellung (ME): Es soll die Markeneinstellung gemessen werden. 
- Kaufabsicht (KA): Es soll die Kaufabsicht gemessen werden. 

Somit haben wir ein relativ einfaches Modell mit vier Konstrukten und vier Wirkungsbeziehungen: 

- TM und SM beeinflussen ME 
- ME beeinflusst KA
- SM beeinflusst KA


### Daten einlesen

```{r}
# Einlesen der Daten
load(url("http://gansser.de/data/SMI.Rdata"))

# Paket Mosaic laden
library(mosaic)
```


### Daten einlesen und inspizieren {.shrink}

```{r}
inspect(data)
```


### Operationalisierung TM und SM

Skala von 1 = stimme überhaupt nicht zu bis 7 = stimme voll und ganz zu.

- TM
  - Ich bin zufrieden mit der Werbung von Firmen und deren Marken in traditionellen Medien wie Radio oder Fernsehen.
  - Die Werbung von Unternehmen und deren Marken in traditionellen Medien wie Radio oder Fernsehen erfüllt meine Erwartungen.
  - ch favorisiere ganz bestimmte Kampagnen von Unternehmen und deren Marken in traditionellen Medien wie Radio oder Fernsehen. 
  
- SM
  - Ich bin mit den erhaltenenen Informationen von Influencern über eine bestimmte Marke in Instagram zufrieden.
  - Die Informationen von Influencern erfüllen meine Erwartungen.
  - Im Vergleich zu anders erhaltenen Informationen sind Informationen in Instagram über eine bestimmte Marke akzeptabel.
  
  
### Operationalisierung TM und SM

Skala von 1 = stimme überhaupt nicht zu bis 7 = stimme voll und ganz zu.

- ME
  - Marken empfinde ich als angenehm.
  - Marken sind bekannt und glaubwürdig.
  - Marken haben positive Eigenschaften.
  
- KA
  - Ich favorisiere den Kauf eines ganz bestimmten Produkts/Marke.
  - Ich bin bereit dieses bestimmte Produkt/Marke anderen zu empfehlen.
  - Ich beabsichtige, ein von Influencern empfohlenes Produkt/Marke in Zukunft zu kaufen.
  

### Korrelationen von SM


```{r}
# Korrelation des Indikators "Social Meldia Influencer"
# Auswahl der Variablen 5 bis 7 im Datensatz
cor(data[, 5:7])
```


### PCA Plot des Indikators SM

```{r echo=TRUE, out.width = "50%", fig.align="center"}

# Laden plsdepot (zuerst install.packages("plsdepot"))
library(plsdepot)
# PCA mit der Funktion nipals
SM_pca = nipals(data[,5:7])
# Plot
plot(SM_pca, main = "SM Indicator (Korrelationskreis)",
cex.main = 1)

```


### Definition des Pfadmodells

```{r echo=TRUE, out.width = "50%", fig.align="center"}
# Pfadmodell (Inneres Modell=> untere Triangel einer Matrix)
TM <- c(0, 0, 0, 0)
SM <- c(0, 0, 0, 0)
ME <- c(1, 1, 0, 0)
KA <- c(1, 1, 1, 0)

path = rbind(TM, SM, ME, KA)
# Optionale Spaltennamen hinzufügen
colnames(path) = rownames(path)
# wie sieht es aus?
path
```


### Graphisches Modell

```{r echo=TRUE, fig.align="center", out.width="100%"}
# Plotten der inneren Matrix
innerplot(path)
```


### Äußeres Modell {.shrink}

```{r}
# Liste, die angibt, welche Variablen mit welchen 
# latenten Variablen verknüpft sind.
blocks = list(2:4, 5:7, 8:10, 11:13)

# Alle latenten Größen werden reflektierend gemessen 
# (formativen Modelle werden als "B" definiert)
modes = rep("A", 4)
```


### Durchführung des PLS Analyse {.shrink}

```{r}
pls = plspm(data, path, blocks, modes = modes)
pls
```


### Prüfung der Unidimensionalität der reflektierenden Blöcke

```{r}
# Überprüfung der Unidimensionalität
pls$unidim
```

- Alle Kriterien der Unidimensiononalität sind erfüllt
- C.alpha > 0,7; DG.roho > 0,7 und die Eigenwerte der ersten Komponente sind wesentlich größer als 1.


### Plot der äußeren Ladungen

```{r echo=TRUE, out.width = "80%", fig.align="center"}
plot(pls, what = "loadings", arr.width = 0.1) 
```

- Sind alle Ladungen größer als 0,7 oder gibt es sogar negative Ladungen?
- Sollen negative Ladungen vorliegen, sind diese Items eventuell zu recodieren.  

### Prüfung des äußeres Modells

```{r }
pls$outer_model
```


### Bewertungskriterien für das äußere Modell


- Zulässige Werte für die **Ladungen** sind Werte größer als 0,7. 
- Äquivalent werden **Kommunalitäten** größer als 0,7^2 = 0,49 als akzeptabel angesehen. Da Kommunalitäten die Höhe der Variabilität repräsentieren, die durch eine latente Variable erklärt wird, bedeutet Kommunalität größer als 0,5, dass mehr als 50% der Variabilität in einem Indikator durch sein latentes Konstrukt erfasst wird. 
- Die **Redundanz** misst den Prozentsatz der Varianz von Indikatoren in einem endogenen Block, der aus den unabhängigen latenten Variablen, die mit dem endogenen Konstrukt assoziiert sind, vorhergesagt wird. Hohe Redundanz bedeutet hohe Prognosefähigkeit


### Plot der Ladungen - code

```{r eval=FALSE}
# Laden ggplot2 (vorher install.packages())
library(ggplot2)
# Barchart der Ladungen
ggplot(data = pls$outer_model,
aes(x = name, y = loading, fill = block)) +
geom_bar(stat = 'identity', position = 'dodge') +
# Grenzwertlinie (um akzeptable Belastungen über 0,7 zu erreichen)
geom_hline(yintercept = 0.7, color = 'gray50') +
# Titel
ggtitle("Ladungen der Items") +
# Name der x-Achse
theme(axis.text.x = element_text(angle = 90))
```


### Plot der Ladungen

```{r echo=FALSE, out.width = "80%", fig.align="center"}
# Laden ggplot2 (vorher install.packages())
library(ggplot2)
# Barchart der Ladungen
ggplot(data = pls$outer_model,
aes(x = name, y = loading, fill = block)) +
geom_bar(stat = 'identity', position = 'dodge') +
# Grenzwertlinie (um akzeptable Belastungen über 0,7 zu erreichen)
geom_hline(yintercept = 0.7, color = 'gray50') +
# Titel
ggtitle("Ladungen der Items") +
# Name der x-Achse
theme(axis.text.x = element_text(angle = 90))
```


### Kreuzladungen - code {.shrink}

```{r eval=FALSE}

# Laden von reshape (vorher install.packages())
library(reshape)

# Datenmatrix für Kreuladungen generieren
xloads = melt(pls$crossloadings, id.vars = c("name", "block"), 
              variable_name = "LV")

# Barcharts der Kreuzladungen je Block
ggplot(data = xloads,
       aes(x = name, y = value, fill = block)) +
  geom_hline(yintercept = 0, color = "gray75") +
  geom_hline(yintercept = c(-0.5, 0.5), color = "gray70", 
             linetype = 2) +
  geom_bar(stat = 'identity', position = 'dodge') +
  facet_wrap(block ~ LV) +
  theme(axis.text.x = element_text(angle = 90),
        line = element_blank()) +
  ggtitle("Crossloadings")
```


### Kreuzladungen

```{r echo=FALSE, out.width = "90%", fig.align="center"}

# Laden von reshape (vorher install.packages())
library(reshape)

# Datenmatrix für Kreuladungen generieren
xloads = melt(pls$crossloadings, id.vars = c("name", "block"), variable_name = "LV")

# Barcharts der Kreuzladungen je Block
ggplot(data = xloads,
       aes(x = name, y = value, fill = block)) +
  geom_hline(yintercept = 0, color = "gray75") +
  geom_hline(yintercept = c(-0.5, 0.5), color = "gray70", linetype = 2) +
  geom_bar(stat = 'identity', position = 'dodge') +
  facet_wrap(block ~ LV) +
  theme(axis.text.x = element_text(angle = 90),
        line = element_blank()) +
  ggtitle("Crossloadings")
```


### Pfadkoeffizienten

```{r}
# Pfadkoeffizioen
pls$path_coefs
```


### Inneres Modell

```{r}
# Inneres Modell
pls$inner_model
```

### Plot der Pfadkoeffizienten im Modell

```{r echo=TRUE, out.width = "90%", fig.align="center"}
plot(pls)
```


### Effekte

```{r}
# effects
pls$effects

```


### Effekte - graphisch

```{r}
# "aktive" Effects in Matrix Format
path_effs = as.matrix(pls$effects[2:6, 2:3])

# rownames zu path_effs hinzufügen
rownames(path_effs) = pls$effects[2:6, 1]

# Wie sieht path_effs aus?
path_effs
```



### Totale und indirekte Effekte - graphisch - code

```{r eval=FALSE}

# Barplots der Total Effekte (direkt + indirekt)
barplot(t(path_effs), border = NA, col = c("#9E9AC8", "#DADAEB"),
        las = 2, cex.names = 0.8, cex.axis = 0.8,
        legend = c("Direct", "Indirect"),
        args.legend = list(x = "top", ncol = 2, border = NA,
                           bty = "n", title = "Effects"))

```


### Totale und indirekte Effekte - graphisch 

```{r echo=FALSE, out.width = "90%", fig.align="center"}

# Barplots der Total Effekte (direkt + indirekt)
barplot(t(path_effs), border = NA, col = c("#9E9AC8", "#DADAEB"),
        las = 2, cex.names = 0.8, cex.axis = 0.8,
        legend = c("Direct", "Indirect"),
        args.legend = list(x = "top", ncol = 2, border = NA,
                           bty = "n", title = "Effects"))

```


### Inneres Modell Zusammenfassung

```{r}
pls$inner_summary
```


### GoF

- Das letzte Maß für die Qualität ist der sogenannte **GoF-Index**, der in $gof enthalten ist. Dies ist eine Pseudo-Goodness-of-Fit-Messung, die versucht, die Gesamtqualität sowohl bei der Messung als auch bei dem Strukturmodell zu berücksichtigen.
- Grundsätzlich bewertet GoF die gesamte Vorhersageleistung des Modells unter Berücksichtigung der Kommunalität und der R^2-Koeffizienten.

```{r}
# gof Index
pls$gof
```



```{r finish-PLS-PM, include=FALSE}
rm(pathToImages)

detach("package:reshape", unload = TRUE)
detach("package:plsdepot", unload = TRUE)
detach("package:plspm", unload = TRUE)
finalizePart(partname)
```
