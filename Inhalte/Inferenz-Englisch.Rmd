
```{r setup-Inferenzstatistik-Englisch, echo=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Karsten Luebke
#%
# ---------------------------------------------------------------------------
source("../prelude.R")
initPart(
    "Inferenz",  # Dateiname ohne Suffix
    "EinfuehrungInferenz"      # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages <- getPathToImages()
# --------------------------------------------------------------------------

library(mosaic)
library(knitr)
library(kableExtra)
library(readr)



tips <- assertData("tips.csv", "https://goo.gl/whKjnl")

```

# Statistical inference using simulation techniques

## Introductory example


### Exercise `r nextExercise()`: Smiling and leniency {.exercise type=essay}

The paper of LaFrance and Hecht^[LaFrance, M., & Hecht, M. A. (1995). *Why smiles generate leniency*. Personality and Social Psychology Bulletin, 21(3), 207-214, https://doi.org/10.1177%2F0146167295213002] investigates whether a smile induces leniency.


- What study type is appropriate for this type of question?
- Which *two* hypotheses are involved? Which one is the more *sceptic* one?
- What would be a rationale to decide on the hypothesis based on the data at hand?



1.  [Think:]{.cemph} Make up your mind, individually.
2.  [Pair:]{.cemph} Pair up your thoughts with a neighbour.
3.  [Share:]{.cemph} Share your ideas with the group.

::: {.notes}

- To control for the effect of covariates, it makes sense to conduct a randomized controlled trial, where one half of the participants will be presented a photo of a smiling person, whereas the second half will be presented a more "neutral" photo. Then the average difference in leniency between the groups can be compared.
- The sceptic hypothesis states that smiling does not cause leniency, ie, there should be no difference between the groups. The alterative hypothesis states the opposite, ie., posits an causal effect of smiling on leniency.
- If the data does not fit well to the hypothesis to the sceptic, ie., $\bar{x}_{\text{smiling}}-\bar{x}_{\text{neutral}}>0$, we may have some evidence *against* the sceptic hypothesis.


:::


### Smiling and leniency

```{r smile, echo=FALSE, fig.align="center", out.width="80%"}
set.seed(1896)
# LaFrance, M., & Hecht, M. A., "Why smiles generate leniency", Personality and Social Psychology Bulletin, 21, 1995, 207-214.

nachsichtigkeit <- c(7, 3, 6, 4.5, 3.5, 4, 3, 3, 3.5, 4.5, 7, 5, 5, 7.5, 2.5, 5, 5.5, 5.5, 
                     5, 4, 5, 6.5, 6.5, 7, 3.5, 5, 3.5, 9, 2.5, 8.5, 3.5, 4.5, 3.5, 4.5, 
                     2, 4, 4, 3, 6, 4.5, 2, 6, 3, 3, 4.5, 8, 4, 5, 3.5, 4.5, 6.5, 3.5, 
                     4.5, 4.5, 2.5, 2.5, 4.5, 2.5, 6, 6, 2, 4, 5.5, 4, 2.5, 2.5, 3, 6.5)
gesicht <- factor(rep(c("lächeln", "neutral"), each =34), levels = c("neutral", "lächeln"))
Lächeln <- data.frame(gesicht, nachsichtigkeit)


Lächeln.shuffle <- do(12) * Lächeln
Lächeln.shuffle <- Lächeln.shuffle %>%
  group_by(.index) %>%
  mutate(gesicht = shuffle(gesicht)) %>%
  ungroup() %>%
  select(-.row)

Lächeln.org  <- Lächeln  %>%
  mutate(.index = 3)

Lächeln.shuffle[Lächeln.shuffle$.index==3, ] <- Lächeln.org


gf_jitter(nachsichtigkeit ~ gesicht, 
          color = ~ gesicht, data = Lächeln.shuffle, width=0.1, height = 0.05, alpha = 0.5) %>%
  gf_point(nachsichtigkeit ~ gesicht, color = ~ gesicht, data = Lächeln.shuffle,
           group = ~ gesicht, stat="summary", size = 4) +
  facet_wrap(~ .index, ncol = 4) +
  ggthemes::scale_color_colorblind() +
  labs(x= "face", y = "leniency", color = "face")
```





### Exercise `r nextExercise()`: Models and their data {.exercise type=essay}

```{r, echo=FALSE, fig.align="right", out.width="20%"}
gf_jitter(nachsichtigkeit ~ gesicht, 
          color = ~ gesicht, data = Lächeln.shuffle, width=0.1, height = 0.05, alpha = 0.5) %>%
  gf_point(nachsichtigkeit ~ gesicht, color = ~ gesicht, data = Lächeln.shuffle,
           group = ~ gesicht, stat="summary", size = 4) +
  facet_wrap(~ .index, ncol = 4) +
  ggthemes::scale_color_colorblind() +
  labs(x= "face", y = "leniency", color = "face")
```

*Eleven* of the panels show data with *no* difference in leniency when comparing smiling vs. neutral faces. *One* panel shows the empirical (observed) data.

Do you find the real, empirical data? Which panel is it?



::: {.notes}
Real data are depicted in panel $3$.


Note that for the real, empirical data: $\bar{x}_{\text{lächeln}}=`r round(mean(nachsichtigkeit ~ gesicht , data = Lächeln)[2],1)`$ und $\bar{x}_{\text{neutral}}=`r round(mean(nachsichtigkeit ~ gesicht , data = Lächeln)[1],1)`$ and hence $\bar{x}_{\text{lächeln}}-\bar{x}_{\text{neutral}}=`r round(diffmean(nachsichtigkeit ~ gesicht , data = Lächeln),1)`>0$. But even if $\mu_{\text{lächeln}}-\mu_{\text{neutral}}=0$ would hold in the population (that's what all the other panels depict) there could be observed differences in the samples. 
:::



### Exercise `r nextExercise()`: Interpretation {.exercise type=essay}


```{r smiledot, echo=FALSE, fig.align="right", out.width="40%"}
set.seed(1896)
Nullvtlg <- do(100)*diffmean(nachsichtigkeit ~ shuffle(gesicht), data = Lächeln)
gf_dotplot( ~ diffmean, data = Nullvtlg, binwidth = 0.05) %>%
  gf_vline(xintercept = ~diffmean(nachsichtigkeit ~ gesicht , data = Lächeln)) %>%
  gf_lims(x=c(-1.2,1.2)) %>%
  gf_labs(y="No simuilations", x="Differences of means")
```

$100$ simulation of the model *no (zero) difference* yield `r tally( ~ diffmean>=diffmean(nachsichtigkeit ~ gesicht , data = Lächeln), data = Nullvtlg)[1]`$\times$ differences between the two groups where the average difference was at least as strong as in the observed data.

How would you interpret this finding?


::: {.notes}
One possible interpretation: If we posit -- based on theoretical assumptions, ie., a theory -- that there are no (zero) differences between the two groups, then the observed data are possible but quite unlikely. On that grounds we doubt the assumptions of zero differences. Thus we have some evidence to believe that there may be indeed a difference between the two groups.
:::





## Statistical modeling and simulation

### One fundamental idea of statistics


- Statistics can be described as the process of gaining insights from data. 

- More precisely, we note that

    - variation is ubiquitiuos
    
    - there will be noise, and signal, if we ware lucky (data = signal + noise)
    
    - Insights are subject of uncertainty
    




### Descriptive statistics vs. inferential statistics


- The job of *descriptive* statistics is to summarize data of a sample.

- The job of *inferential* statistics is to generalize from a sample to a population.^[logical induction]

\vspace{1cm}

```{r fig-desk-vs.inf, out.width="70%", echo = FALSE}
knitr::include_graphics(file.path(pathToImages,"desk_vs_inf-crop.png"))
```


### Inference

[Idea:]{.cemph} Generalize from a random sample to the respective population by means of:

- point estimation
- confidence intervals
- hypothesis testing



[Objective:]{.cemph} Posit propositions that not only apply to the sample at hand, but to the population in general -- considering uncertainty of inference.^[See  Moore, D. (2007) The Basic Practice of Statistics, 4th edn. New York: Freeman, S. xxviii.]


### Triangle test


Consider three probes, where

- two are identical, and one -- randomly chosen -- is different.
- a candidate tries to identify the different probe.^[cf. ISO 4120 [https://www.iso.org/standard/33495.html](https://www.iso.org/standard/33495.html)]

```{r, echo=FALSE, fig.align="center", out.width="30%"}
plot(c(1,2,3), y=c(1,sqrt(5),1), 
     col=c("darkgreen", "red", "red"), 
     pch=c(3,4,4), cex=8, lwd=8, ann=FALSE, axes=FALSE, xlim = c(0,4), ylim = c(0,3), asp = 1)
```


### Exercise `r nextExercise()`: Scales of measurement {.exercise type=A-B answer=A}

Which scale level has the attribute "probe" with the values "correct" and "false"?


A.  categorical
B.  numeric


::: {.notes}
Probe" is a categorical attribute (***A***). Notably, there are only two there are two distinct values only. Attributes of this kind are called *binary*. Such attributes may be modelled using formal logic:  "Probe correctly identified?" No, Yes? $0,1$.
:::


### Bar as the better lecture hall

During a special lecture at the FOM Dortmund (Oct. 6, 2016)^[[https://www.fom.de/2016/oktober/kneipe-statt-hoersaal-chef-mit-humor-lohnt-sich.html](https://www.fom.de/2016/oktober/kneipe-statt-hoersaal-chef-mit-humor-lohnt-sich.html)] and Münster (Nov., 11, 2016), out of $n=34$ participants, $x=12$ correctly identified the correct probe at the triangle test.


```{r echo=FALSE, out.width = "35%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages,"Lidl-WR20160919.png"))
```
[Source: Anzeige Westfälische Rundschau, 19.9.2016]{.small}




## Point estimate 

### Point estimate -- bar as the better lecture hall

- The $n=34$ participants are a **sample**.

- We are interested in whether *in general* there is a difference between the probes, ie., we would like to **generalize** to a population.

- The proportion of those in the population who correctly identify the probe is denoted by $\pi$, whereas the corresponding proportion in the sample will be denoted by $p$.

- As $\pi$ is nearly always unknown, it must be **estimated** using the sample data: $\hat{\pi}$.




### Exercise `r nextExercise()`: Point estimation {.exercise type=A-B-C-D answer=C}

What you think is a sensible estimate for $\pi$?


A.  $\hat{\pi}=\frac{1}{2}$
B.  $\hat{\pi}=\frac{1}{3}$
C.  $\hat{\pi}=\frac{12}{34}$
D.  No answer is possible.


::: {.notes}
Response ***C*** is correct. In the sample there are $12$ out of $34$ who have identified the correct probe. This value of $12/34$ is used as the point estimate for the value in the population.
:::


### Point estimation

The value of the sample is frequently used as an **point estimate** of the corrsponding value in the population, eg.,

  - proportion (categorical data): Population $\pi$, sample $p$, point estimate $\hat{\pi}=p$.

  - arithmetic mean (numerical data): Population $\mu$, sample $\bar{x}$, point estimate $\hat{\mu}=\bar{x}$.

  - correlation coefficient (numerical data): Population $\rho$, sample $r$, point estimate $\hat{\rho}=r$.


The *hat* symbol ($\hat{}$) indicates that an unknown true value was estimated. Point estimates are based on sample values. 



### Exercise `r nextExercise()`: Results of an point estimate {.exercise type=yesno answer=no}

Are we ceratin that the following holds:  $\pi=\hat{\pi}=p=\frac{12}{34}$



- Yes.

- No.

::: {.notes}
A different sample may yield a different result. Hence, we are uncertain about the true value in the population, ie., **No**.
:::


### Standard error

- Point estimates vary with the sample from which they are estimated. The **standard error** ($se$) quantifies the variation (standard deviation, sd) of a point estimate, eg., arithmetic mean:  $\bar{x}$: $se=\frac{sd}{\sqrt{n}}$.

- The $se$ decreases with increasing sample size $n$ (ceteris paribus).

- As point estimates will vary, **interval** estimates are more frequently used.



### FOMshiny: Sampling {include-only=shiny}


Based on population data: How does the distribution of a statistic (of the sample) evolve (e.g., mean or proportion)?


[https://fomshinyapps.shinyapps.io/Sampling/](https://fomshinyapps.shinyapps.io/Sampling/)






## Confidence interval

### Sampling distribution (I/ III)

*Assume* our triangle test sample comes from a population of $N=340000=220000+120000$, where it holds true that $\pi=\frac{12}{34}=`r 12/34`$, ie., $220000$ are wrong (`f`), $120000$ identify correctly (`t`):


```{r}
population <- rep(factor(c("f","t")), c(220000, 120000))
prop( ~ population, success = "t")
```

Dann kann auch der Anteil in der Stichprobe: `sample` ($n=34$) variieren:

The proportion of successes will vary sample by sample. Try it:

```{r, eval=FALSE}
prop( ~ sample(population, size = 34), success = "t")
prop( ~ sample(population, size = 34), success = "t")
```

```{r, echo=FALSE, cache=0}
set.seed(1904)
prop( ~ sample(population, size = 34), success = "t")
prop( ~ sample(population, size = 34), success = "t")
```


###  Sampling distribution (II/ III)

Simulating $10^5$ random samples from the population:

```
Initialize randomizer 
sample_distro is defined as 
  - repeat 10000 times:
    - Compute the proportion of "t"
    - Based on a draw of size 34 from the population
```

```{r}
set.seed(1896) # Reproduzierbarkeit
sample_distro <- do(10000)* prop( ~ sample(population, size = 34), 
                               success = "t")
```

Simulated standard error ($se$):

```{r}
sd( ~ prop_t, data = sample_distro)
```


### Sampling distribution  (III/ III)

```{r, fig.align="center", out.width="60%"}
gf_bar( ~ prop_t, data = sample_distro)
```


### Übung `r nextExercise()`: Proportion {.exercise type=A-B-C answer=C}

```{r, echo=FALSE, fig.align="right", out.width="20%"}
gf_bar( ~ prop_t, data = sample_distro)
```


If it is true that  $\pi=\frac{12}{34}$, what's the proportion $p$ that is most likely in the samples?


A.  $p=\frac{1}{2}$
B.  $p=\frac{1}{3}$
C.  $p=\frac{12}{34}$


::: {.notes}
***C***: It is even sometimes true that $p=\hat{\pi}=\pi$. However smaller deviations do occur frequently; larger deviations less frequently. Sadly, we do not know what the case is for our present sample.

For (quasi-)continuous distribution the following holds:   $\hat{\mu}\neq \mu$. 
:::


### Resampling 


Most often, we do not know the value of the population. But we can **resample** our sample -- *using sampling with replacement*. See:



::: {.small}

```{r, eval=FALSE}
my_sample <- rep(factor(c("f","t")), c(22, 12))
my_sample
```
```{r, echo=FALSE}
my_sample <- rep(factor(c("f","t")), c(22, 12))
names(my_sample) <- 1:length(my_sample)
my_sample
```

```{r, eval=FALSE}
resample(my_sample)
```


```{r, echo=FALSE}
set.seed(1896)
rstipro <- resample(my_sample)
rstipro <- my_sample[sort(as.numeric(names(my_sample)))]
rstipro
```

:::


### Resampling: Proportion

```{r}
set.seed(1896) # reproducibility
do(3)* prop( ~ resample(my_sample), success = "t")
```


### Schema: Bootstrap

```{r echo=FALSE, out.width = "70%", fig.align="center"}
knitr::include_graphics(file.path(pathToImages, "bootstrap.png"))
```

[Image: Source: Lock, Robin, Patti Frazer Lock, Kari Lock Morgan, Eric F. Lock, and Dennis F. Lock (2012): Statistics: UnLOCKing the Power of Data. Wiley.]{.small}


### Introducing the Bootstrap

[Assumptions:]{.cemph}

- Randomly drawn sample (or random allocation to groups)
- At least moderate sample size $n\geq 35$



[Example:]{.cemph} Bootstrap Percentile Interval^[There are more variants available, in parts yielding more precise estimations in some situations.] for estimating one parameter from a sample of size $n$:


- Repeat many times  (eg., $10000 \times$)
    - Sample  with replacement of size $n$ from the original sample
    - Compute statistic of interest (eg., proportion) based on the bootstrap sample
- Plot a histogram of the bootstrap distribution of the statistic
- The $95\,\%$ bootstrap interval consists of the "middle"  $95\,\%$ of the bootstrap distribution


### FOMshiny: Resampling {include-only=shiny}

Based on a (real, observed) sample: Where does the bootstrap distribution come from?

[https://fomshinyapps.shinyapps.io/Resampling/](https://fomshinyapps.shinyapps.io/Resampling/)






### Übung `r nextExercise()`: Bootstrap {.exercise type=yesno answer=yes}


True or false: During resampling, one given case my be drawn more than once into the bootstrap sample?

- True

- False

::: {.notes}
***TRUE***: Drawing with replacement includes the possibliity that one given case from the original sample will be sampled more than once. As the cases are "put back" into the original sample, the possibility of one given case remains constant for each of the $n$ drawings.
:::


### Bootstrap distribution (I/ II)

```
initialize randomizer
define boot_distro as:
  - Repeat 10000 times:
    - Compute the proportion of "t",
    - where the dataset "my_sample" is to be resampled each time
```

```{r}
set.seed(1896)
boot_distro <- do(10000)* prop( ~ resample(my_sample), 
                             success = "t")
```


###  Bootstrap distribution  (II/ II)

```{r, fig.align="center", out.width="60%"}
gf_bar( ~ prop_t, data = boot_distro)
```


### Comparing Sampling and resampling

If the distribution of the sample is *similar* to the population, we can approximate the population using resampling (simulation) techniques.


```{r, echo=FALSE, fig.align="center", out.width="60%"}
p1 <- gf_bar( ~ prop_t, data = sample_distro, title = "Sample distribution")
p2 <- gf_bar( ~ prop_t, data = boot_distro, title ="Bootstrap distribution")


Stichprobenverteilung <- sample_distro$prop_t
Bootstrapverteilung <- boot_distro$prop_t
values <- c(sample_distro, boot_distro)
types <- c(rep("Stichprobenvtlg", length(sample_distro)), rep("Bootstrapvtlg", length(boot_distro)))
df <- data.frame(values, types)



gridExtra::grid.arrange(gridExtra::grid.arrange(p1,p2, ncol=2))
```


### Bootstrap confidence interval

- The uncertainty in statistical results is partly due to the "randomness" of the sample at hand.

- This uncertainty can be simulated using resampling techniques.

- The $95\,\%$ confidence interval is the interval in which  $95\,\%$ of our resampled statistics fall:

```{r}
quantile( ~ prop_t, data = boot_distro, probs = c(0.025, 0.975))
```


### Exercise `r nextExercise()`: Plausible values {.exercise type=yesno answer=no}

```{r}
quantile( ~ prop_t, data = boot_distro, probs = c(0.025, 0.975))
```


Considering our sample: Do you consider a proportion of  $\frac{1}{3}$ as *implausible*?


- Yes

- No


::: {.notes}
***No***: This value was covered by the confidence interval. That means we found samples of this value quite frequently during our resampling procedure. We do *not* have evidence in our sample against $\frac{1}{3}$.
:::


### Exercise `r nextExercise()`: Confidence interval {.exercise type=A-B answer=B}


What is a confidence interval referring to?


A. Referring to values of observations, $x_i$.

B. Referring to values of populations, e.g., $\pi, \mu$.



::: {.notes}

***B***: Confidence intervals describe the uncertainty when estimation populations.

Whereas the point estimates can be described as fishing-rod that fishes one certain values, the confidence intervals can be likened to a fishing-net that yields a range of compatible values.
:::


### Confidence interval


- A **confidence interval** (CI) denotes an interval that covers the true (but unknown) value with a pre-specidied confidence (eg. $95\,\%=1-\alpha=100\,\%-5\,\%$)^[The \%-value is often an approximation only.], ie., the proportion of confidence intervals constructed in this way that include the true value.^[Song [https://www.causeweb.org](https://www.causeweb.org): [Larry Lesser &copy; Call It Maybe](https://www.causeweb.org/cause/resources/fun/songs/call-it-maybe)]

- A typical vlaue for $n>30$: $95\,\%$-CI $\approx \delta^* \pm (2 \cdot se)$,ie., for the mean value: $95\,\%$-KI für $\mu$: $\approx \bar{x} \pm 2 \cdot se = \bar{x} \pm 2 \cdot \frac{sd}{\sqrt{n}}.$

- The confidence gets more narrow with the sample size increasing (c.p.) as the $se$ decreases with $n$.

- The higher the confidence (e.g., $99\,\%$ in lieu of $95\,\%$), the larger larger the interval.



### Exercise `r nextExercise()`: Width of the confidence interval {.exercise type=yesno answer=no}

True or false: The width of the confidence interval is *not* related to the variation of the variable under investigation?

- Yes.

- No.

::: {.notes}

***No***: In additon to the uncertainty induced by the random drawing of the sample, the variation of the variable under investigation induces further uncertainty.

Note that the $sd$ is part of this formula:  $\bar{x} \pm 2 \cdot \frac{sd}{\sqrt{n}}$
:::


### Confidence interval coverage

```{r, echo=FALSE, , fig.align="center", out.width="80%"}
set.seed(1896) # Reproduzierbarkeit
CIsim(n=10, samples=100)    
```


### Sebastians Kaffeemühle {include-only=sesmill}

::: {.flush align=top-right}

```{r echo=FALSE, out.width = "20%", fig.align="right"}
knitr::include_graphics(file.path(pathToImages, "maschine.jpg"))
```

:::

- Die Sicherheit (Konfidenz) drückt die *Performance* der Maschine nach Konstruktion aus: Wenn oft neue Bohnen (Stichproben) eingefüllt werden, wird in $1-\alpha$ der Fälle die wahre "Essenz" (z. B. $\pi$) innerhalb des Kaffees (Konfidenzintervall) liegen.
- Ob dies bei unserem Kaffee der Fall ist, wissen wir nicht.^[Skizze: Sebastian Sauer]





### FOMshiny: Konfidenzintervall {include-only=shiny}

Factors influencing the width of a confidence interval:


[https://fomshinyapps.shinyapps.io/Konfidenzintervall/](https://fomshinyapps.shinyapps.io/Konfidenzintervall/)









## Conclusion 

### Cartoon: Statistics

```{r echo=FALSE, out.width = "50%", fig.align="center", cache=FALSE}
# Lizenzworkaround: 
extern_image_include("https://www.causeweb.org/cause/sites/default/files/caption_contest/2018/Caption-Contest_09-2018.jpg", "cartoon0918.jpg", pathToImages)
```



"A bit difficult to fully digest, but very nutritional and packed with vitamins sigma! $\alpha, \hat{\pi}, \bar{x}$ und besonders $\mu$ and $\sigma$."^[[https://www.CAUSEweb.org/](https://www.causeweb.org/cause/caption-contest/september/2018/results) &copy; J.B. Landers, Überschrift G. Baugher]


### Distrbutions {.shrink}

A distribution tells us how *frequent* (likely) a *given value* (range) is.

1. Distribution of a population
  *Example*: What's the proportion $\pi$ among all students preparing for the next lecture?

2. Distribution of a sample
  *Example*: What's the proportion $p$ of the students in a sample who prepared for the next lecture?

3. Sampling distribution
  *Example*: What's the average proportion $p$ of students (preparing ...) in the random samples?
  
4. Resampling distribution
  *Example*: What's the average proportion $p$ of students (preparing ...) in the random *re*samples?
  
5. Null distribution
  *Example*: What are likely values of proportions given the $H_0$ is true?




### Exercise `r nextExercise()`: Distributions {.exercise type=A-B-C-D-E answer=B}

Im Rahmen einer Datenanalyse: Welche Verteilung können Sie beobachten?

Which of the following distributions is *empirically observable* during a data analysis project?


A.  Distribution of the population
B.  Distribution of the sample
C.  Sampling distrubtion
D.  Resampling distribution
E.  Null distribution


::: {.notes}
***E***: The empirical sample is observable; the rest are theoretical or assumed or simulated distributions.

:::


### Simulation based inference as an overarching principle

- Simulation based inference (SBI) provides *one* method for a variety of questions of statistical inference.

**Alternatively** one may work with theoretically devised distributional assumptions (such as $t$-, $F$ or $\chi^2$).

- Each of such "classical" tests builds on a own rationale and set of assumptions.

- Note that there are cases for which the appropriate theoretical distributions are unknown.


### Using statistics for generalization


- Randomly drawn sample: Increased external validity

- Randomly assigned to groups: Increased internal validity



```{r echo = FALSE, message = FALSE, eval = TRUE, cache = FALSE}
d <- read_csv("../Inhalte/StatisticalLearning/Zufall-Schluesse-Englisch.csv")


d %>% 
  kable(escape = FALSE, booktabs = TRUE) %>% 
  kable_styling() %>% 
  column_spec(1, width = "3cm") %>% 
  column_spec(2, width = "3cm") %>% 
  column_spec(3, width = "5cm") %>% 
  column_spec(4, width = "5cm")
```



### Overview on simulation techniques

- **Simple simulation** for testing/estimating single parameters values (eg., proportions)
    - [Example:]{.cemph} What's the proportion of females ($\pi$) in the population? 
    - [Procedure:]{.cemph} Simulate many coin flips and count how many flips are as extreme as empirical proportion.

- **Permutation test** for testing associations between two variables (eg., differences in means)
    - [Example:]{.cemph} Is there a difference in means between smokers and non-smokers?
    - [Procedure:]{.cemph} Simulate many random allocations to the groups and count how many samples are as extreme as empirical difference.

- **Bootstrap** for estimating a confidence interval (eg., mean values)
    - [Example:]{.cemph} What are plausible values of total bill?
    - [Procedure:]{.cemph} Simulate many resampled samples and devise the range of typical results.
    


### FOMshiny: Permutation {include-only=shiny}

Watch the evolution of "shuffling" (permutation) samples:

[https://fomshinyapps.shinyapps.io/Permutation/](https://fomshinyapps.shinyapps.io/Permutation/)



### Overview on (test) statistics


```{r echo = FALSE, message = FALSE, eval = TRUE, cache = FALSE}


d <- read_csv("../Inhalte/StatisticalLearning/teststatistics.csv")


d %>% 
  kable(escape = FALSE, booktabs = TRUE) %>% 
  kable_styling() %>% 
  column_spec(1, width = "2cm") %>% 
  column_spec(2, width = "2cm") %>% 
  column_spec(3, width = "6cm")
```





::: {.scriptsize}
binary: two different values: 0 vs 1 or A vs. B.
:::


### Recap: Basic ideas of inference

- [Assumptions:]{.cemph} independent and identically distributed (iid) data 

- `Y ~ 1` (ie., no independent variable): Modelled distribution of $Y$ is based on one parameter value. $H_0$: eg., $\pi=\pi_0$ or $\mu=\mu_0$.
- `Y ~ X`: Distribution of $Y$ is modelled as a function of $X$. $H_0$: Distribution of $Y$ is equal for all values of $X$.
- *Regression* techniques are capable of including multiple independent variables.



Mindmap: [https://coggle.it/diagram/Vxlydu1akQFeqo6-/t/inference](https://coggle.it/diagram/Vxlydu1akQFeqo6-/t/inference)


### Overview on (test) statistics using R `mosaic` 



```{r echo = FALSE, message = FALSE, eval = TRUE, cache = FALSE}
d <- read_csv("../Inhalte/StatisticalLearning/which-test-mosaic.csv")



d %>% 
  kable(escape = FALSE, booktabs = TRUE) %>% 
  kable_styling() %>% 
  column_spec(1, width = "1.8cm") %>% 
  column_spec(2, width = "1.8cm") %>% 
  column_spec(3, width = "4cm") %>% 
  column_spec(3, width = "4cm")
```







- [Permutation test:]{.cemph} `do(often) * statistic(y ~ shuffle(x), data = my_data)`

- [Bootstrap:]{.cemph} `do(often) * statistic(y ~ x, data = resample(my_data))`



Parametric models are based on (strong) distribution assumptions!


```{r finish-Inferenzstatistik, include=FALSE}
rm(pathToImages)
finalizePart(partname)
```

