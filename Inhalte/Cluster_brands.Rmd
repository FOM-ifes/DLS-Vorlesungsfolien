```{r setup-Cluster_brands, include=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Oliver Gansser (oliver.gansser@fom.de)
#%
# ---------------------------------------------------------------------------
source("../prelude.R")
initPart(
    "Cluster_brands",  # Dateiname ohne Suffix
    "Marketingcontrolling"        # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages = getPathToImages()
# ---------------------------------------------------------------------------

library(mosaic)

```

# `r nextChapter()` Clusteranalye zur Marksegmentierung


### Lernziele

- Einsatz und Ziel der Clusteranalyse verstehen.
- Daten für die Clusteranalyse aufbereiten.
- Anwendung der hirarchischen Clusteranalyse.
- Interpretation und Schlussfolgerungen der hirarchischen Clusteranalye.
- Anwendung der Clusterzentrenanalyse.
- Interpretation und Anwendung der Clusterzentrenanalyse.
- Evaluation des Einsates der Clustenalyse in der Marketing Controlling Praxis.


### Verwendung der Clusteranalyse

Die Clusteranalyse wird verwendet um homogene Gruppen (in der Regel Beobachtungen) innerhalb der Daten zu finden.

**Fragestellung**

Welche Gruppen gibt es innerhalb der Daten - und worin unterscheiden sich die Gruppen?

**Ziel der Clusteranalyse**

Das Ziel einer Clusteranalyse ist es, innerhalb der Cluster möglichst homogene Daten zu haben, zwischen den Clustern (extern) möglichst heterogen zu sein. 


### Grundidee der Clusteranalyse

**Schritt 1**: Auswahl der Variablen, die für die Gruppenbildung verwendet werden sollen (z.B. soziodemografische Merkmale, Einstellvariablen, Lebensstilmerkmale).

**Schritt 2:** Verschmelzung jener zwei Cluster, die sich am nächsten sind.

**Schritt 3:** Zusammenfassung der Objekte in homogene Gruppen basierend auf den Werten des Proximitätsgrades unter Anwendung eines Fusionsalgorithmus.


### Übung `r nextExercise()`: Clusteranalyse {.exercise type=A-B-C-D-E answer=C-D}

Was wird bei der Clusteranalyse gecluster? (max. zwei Antworten sind richtig)

A.  Die Variablen
B.  Die Items
C.  Die Beobachtungen
D.  Die Zeilen
E.  Keine der obigen Antworten ist richtig

<div class="notes">
***C und D***
</div>


### Zwei Verfahren der Clusteranalyse

Grundsätzlich gibt es in R zwei Verfahren der Clusteranalyse:

- **Hierarchische Clusterung:** In hierarchischen Clusterverfahren werden Beobachtungen sukzessive zusammengefasst. Jede Beobachtung ist zunächst ein eigener Cluster, der dann nach dem Ähnlichkeitsmaß gruppiert wird.

- **Clusterzentrenanalyse:** Ist ein partionierendes Verfahren, geht von einer gegebenen Gruppierung der Objekte aus und ordnet die Objekte zwischen den Gruppen um, bis ein optimaler Wert einer Zielfunktion (die Summe der Quadrate der Abweichungen der Beobachtungen soll im Cluster zum Clusterzentrum minimiert werden) erreicht ist.


### Einlesen der brand.ratings Daten {.shrink}

```{r}
load(url("http://gansser.de/data/brand/brand.ratings.Rdata"))
head(brand.ratings)
```


### Hierarchische Clusteranalyse - Distanzen berechnen

```{r}
d <- dist(brand.ratings[,-10]) # Distanzmatrix ohne die Markenspalte
as.matrix(d)[1:4,1:4] # Ziege die ersten 5 Zeilen und Spalten
```

Wenn keine weiteren Argumente `dist` agegeben werden, wird immer die Euclid-Metrik verwendet. Wenn in den zu clusternden Daten nicht nur numerische, sondern auch nominale Daten vorhanden sind und diese Daten mit in die Clusterung einbezogen werden sollen, empfielt es sich die `daisy` Funktion zu verwenden. Diese scaliert die Daten ud berechnet dann die Distanzen.


### Übung `r nextExercise()`: Funktion daisy {.exercise type=essay}

Versuchen Sie einmal selbst die Distanzmatrix mit `daisy()` zu berechnen. Was fällt Ihnen auf? Was müssen Sie beachten?

<div class="notes">
Die Funktion daisy() macht nur Sinn, wenn die Daten tatsächlich auch gemischt sind. Im vorliegenden Fall müssen also auch die Markennamen mit einbezogen werden, sonst werden die Daten nicht skaliert. 
</div>


### Hirarchische Clusteranalyse mit Ward Methode {.shrink}

```{r}
library(cluster)
fit <- hclust(d, method="ward.D")  
plot(fit) 
```

Dendrogramme enthalten den **Abstand der beiden Cluster**, die im jeweiligen Schritt **verschmolzen** werden. Wenn nur geringe Zunahmen in diesen Distanzen zu beobachten sind, ist der Übergang auf weniger Cluster vertretbar. Ist die Zunahme stark, ist ein möglicher Stopp des Fusionsprozesses sinnvoll.


### Übung `r nextExercise()`: Cluster-Methodee {.exercise type=A-B-C-D-E-F answer=A-B-C-D-E-F}

Welche Methode für die hirarchische Clusterung lässt sich noch ausführen? Probieren Sie es aus. 

A.  single
B.  complete
C.  avarage
D.  mcquitty
E.  median
F.  centroid

<div class="notes">
***A-B-C-D-E-F***

siehe ?hclust
</div>



### Dendrogramm mit drei Cluster {.shrink}

Da ein Dendrogramm an beliebiger Stelle geschnitten werden kann, muss der Experte die Anzahl der gewünschten Gruppen angeben. Wir können sehen, wo das Dendrogramm geschnitten würde, indem wir seinen `plot()` mit `rect.hclust()` überlagern und die Anzahl der gewünschten Gruppen angeben (k=..).

```{r}
plot(fit)
rect.hclust(fit, k=3, border="red")
```


### Cluster zuweisen

Den Zuweisungsvektor für Beobachtungen erhalten wir mit `cutree()`:

```{r}
brand.segmente <- cutree(fit, k=3)
# gibt uns die Anzalh Beobachtungen je Segment aus
table(brand.segmente) 
```


### Übersicht über die Cluster {.shrink}

```{r}
# Zuordnung in Datensatz schreiben
brand.ratings$hclust <- cutree(fit, k=3)
# Mittelwerte über die drei Cluster ausgeben
aggregate(. ~ hclust, data=brand.ratings, mean)
```


### Übung `r nextExercise()`: Beschreibung Cluster {.exercise type=A-B-C answer=A}

Für welchen Cluster passt die Beschreibung *wertvolle Marke mit hoher Wiederkaufwahrscheinlichkeit* am Besten?

A.  Cluster `1`.
B.  Cluster `2`.
C.  Cluster `3`.

<div class="notes">
Das Clusterzentrum von `3` hat den höchsten Wert in den Variablen `value`, `rebuy` und `brand`, also ***C***.
</div>


### Clusterzentrenanalyse

k-means Schema:

1. Zufällige Auswahl von K Clusterzentren aus den n Beobachtungen und Zuordnung der Beobachtungen zum nächsten Clusterzentrum
2. Berechnung des Clusterzentrums der zugeordneten Beobachtungen (z.B. über Mittelwert)
3. Zuordnung der Beobachtungen zum nächsten Clusterzentrum
4. Falls sich die Zuordnung geändert hat, weiter mit Schritt 2, ansonsten Ende

Da explizit eine mittlere Abweichung berechnetwird, ist k-means Clustering auf euklidische Distanz angewiesen. Daher ist sie **nur für numerische Daten** oder Daten, die sinnvollerweise zu numerischen Daten gezwungen werden können, geeignet. 

### k-means {.shrink}

```{r}
# konvertiert die ganze Matrix numerisch
brand.ratings<-lapply(brand.ratings, as.numeric) 
# und speichert als data.frame ab. 
brand.ratings<-as.data.frame(brand.ratings) 
library(cluster) # wenn noch nicht geladen
class(brand.ratings)
set.seed(1896)
fit <-  kmeans(brand.ratings[,-11], centers = 3) #  3 Clusterlösung

# Clustermittelwerte der Items
fit$centers

# Zuordung der Cluster zum Datensatz
brand.ratings<- data.frame(brand.ratings, fit$cluster)
```


### Plot der finalen Clusterlösung {.shrink}

```{r}
clusplot(brand.ratings[,-11], fit$cluster, color=TRUE, shade=TRUE, 
         labels=4, lines=0, main="K-means cluster plot")
```


### Heatmap {.shrink}

```{r}
heatmap.2(fit$centers,
          col=brewer.pal(9, "Blues"), trace="none", key=FALSE, dend="none",
          Colv=FALSE, cexCol = 1.2, main="Mittelswerte der Clusterlösung")
```



### Literatur

- Chris Chapman, Elea McDonnell Feit (2015): *R for Marketing Research and Analytics*, Kapitel 11.3.1 bis 11.3.4
- Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani (2013): *An Introduction to Statistical Learning -- with Applications in R*, [http://www-bcf.usc.edu/~gareth/ISL/](http://www-bcf.usc.edu/~gareth/ISL/), Kapitel 10.3


```{r finish--Kind-Cluster_brands, include=FALSE}
rm(pathToImages)
finalizePart()
```


