```{r setup-Textmining, include=FALSE}
# ---------------------------------------------------------------------------
#% maintainer:
#%   - Karsten Luebke
#%   - Sebastian Sauer
#
# ---------------------------------------------------------------------------
source("../prelude.R")
initPart(
    "T-Textmining",  # Dateiname ohne Suffix
    "Textmining"     # Verzeichnisname im Bilderverzeichnis 
    )
pathToImages <- getPathToImages()
# ---------------------------------------------------------------------------

library(mosaic)
library(tidyverse)
library(stringr)  # Textverarbeitung
library(tidytext)  # Textmining
library(lsa)  # Stopwörter
library(SnowballC)  # Wörter trunkieren
library(wordcloud)  # Wordcloud anzeigen

```

# Textmining


### Zentrale Begriffe



Die computergestützte Analyse von Texten speiste (und speist) sich reichhaltig aus Quellen der Linguistik; entsprechende Fachtermini finden Verwendung:  

- Ein *Corpus* bezeichnet die Menge der zu analysierenden Dokumente; das könnten z.B. alle Reden der Bundeskanzlerin Angela Merkel sein oder alle Tweets von "\@realDonaldTrump".

- Ein *Token* (*Term*) ist ein elementarer Baustein eines Texts, die kleinste Analyseeinheit, häufig ein Wort.

- Unter einem *Tidytext-Dataframe* versteht man einen Dataframe, in dem pro Zeile nur *ein* Token (z.B. Wort) steht.


### Pakete - vorab ggf. installieren

```{r message = FALSE}
library(mosaic)
library(tidyverse)
library(stringr)  # Textverarbeitung
library(tidytext)  # Textmining
library(lsa)  # Stopwörter
library(SnowballC)  # Wörter trunkieren
library(wordcloud)  # Wordcloud anzeigen
```



### Tidytext -- Input

```{r}
text <- c("Wir haben die Frauen zu Bett gebracht,",
          "als die Männer in Frankreich standen.",
          "Wir hatten uns das viel schöner gedacht.",
          "Wir waren nur Konfirmanden.")
text_df <- tibble(Zeile = 1:4,
                      text = text)
```

### Tidytext -- Output

```{r echo = FALSE}
text_df %>%
  unnest_tokens(output = wort, input = text) -> tidytext_df

knitr::kable(text_df, caption = "Gedicht von Brecht",
booktabs = TRUE)
```

In einem 'tidy text Dataframe'  steht in jeder Zeile ein Wort (bzw. ein token).

### Veranschaulichung eines Tidytext-Dataframes

```{r p-tidytext, fig.align = "center", out.width = "70%", echo = FALSE}
knitr::include_graphics(file.path(pathToImages, "tidytext-crop.png"), error=FALSE)
```

### Text "entschachteln"

```{r}
unnest_tokens(text_df, output = wort, input = text) -> tidytext_df
```


### Nur Textzeichen herausfiltern (keine Ziffern etc.)


```{r}
tidytext_df %>%
  filter(str_detect(wort, "[a-z]")) -> tidytext_df_lowercase
```



### Fallbeispiel AfD-Wahlprogramm

```{r}
afd_url <- paste0("https://osf.io/wn8ft/", "/?action=download")
afd_df <- read_csv(afd_url)
```

Das Dokument wurde mit `pdftools::pdf_text()` von einer PDF-Datei in eine CSV-Datei übertragen.

### Text entschachteln


```{r}
afd_df %>%
  unnest_tokens(output = token, input = content) %>%
  dplyr::filter(str_detect(token, "[a-z]")) -> afd_long
```



```{r}
afd_df %>%
  drop_na() %>%  
  dplyr::count(content, sort = TRUE) %>%
  head(3)
```

### Stopwörter entfernen


```{r show-stopwords}
data(stopwords_de)
stopwords_de <- data_frame(word = stopwords_de)
stopwords_de <- stopwords_de %>%
  rename(token = word)  
afd_long %>%
  anti_join(stopwords_de) -> afd_no_stop
```



### Die drei häufigsten Wörter im AfD-Parteiprogramm


```{r echo = FALSE}
afd_df %>% 
  mutate(token_stem = wordStem(.$content, language = "german")) %>% 
  count(token_stem, sort = TRUE) -> afd_count

afd_count %>% 
  top_n(3)
```


### Wordcloud^[Keine informative Grafik; nur "zum Spaß" verwenden.]

```{r echo = FALSE, fig.cap = "Eine Wordcloud, zum Spaß", out.width = "50%"}
wordcloud(words = afd_count$token_stem, 
          freq = afd_count$n, 
          max.words = 100, 
          scale = c(2,.5), 
          colors=brewer.pal(6, "Dark2"))
```

```{r finish-Textmining, include=FALSE}
finalizePart()
```
